# * Each node has a list of metadata:
# - 1 - pretty name (displayed). Note, the node name/identifier itself is also meaningful as the fieldname in the data struct. 
# - 2 - type (see PropertiesGUIProp.m for options)
# - 3 - isEditable
# - 4 - description
# - 5 - default value
# - 6 - visualization function
# - 7 - level - one of {'Important','Beginner','Advanced','Developer'}. All important features need to be reset for each project. Default values should work for all non-Important features, but better results could potentially be achieved by changing these. The rest of the parameters are split into those that often are helpful to adjust (Beginner), those that should be rarely adjusted (Intermediate), and those that only someone working with a developer should touch. This property is only used for leaf nodes. Level of non-leaf nodes is based on maximum level of children, with important being highest, developer being lowest. 
# - 8 - requirements - some parameters will only be used in certain kinds of projects. list here keys for including these parameters. Non-leaf nodes included if any child node is included. 
# * After the metadata comes a list of child nodes.
# * As a shortcut, leaf nodes can contain the metadata directly as their value.

ROOT:
  - ['','',false,DUMMY,'','','','']
  - ImageProcessing:
    - ['','',false,'Parameters related to initial processing of the input video data before any learning happens. These parameters will affect tracking regardless of the learning algorithm used.','','','','']
    - BackSub:
      - ['Background Subtraction','',false,'Parameters related to foreground/background classification. You should only use background subtraction if (1) The video background is constant, (2) You have a good model of the image background computed using some other tracking software, e.g. Ctrax, and (3) You are seeing tracking errors in which part detections are being predicted on parts of the background that seem to resemble the animal. For example, leg-shaped dust particles in our fly arena could be confused with legs, and background subtraction could help remove these errors.','','','','isCPR']
      - Use: ['Enable',boolean,true,'Whether to use background subtraction or not. You should only use background subtraction if (1) The video background is constant, (2) You have a good model of the image background computed using some other tracking software, e.g. Ctrax, and (3) You are seeing tracking errors in which part detections are being predicted on parts of the background that seem to resemble the animal. For example, leg-shaped dust particles in our fly arena could be confused with legs, and background subtraction could help remove these errors.',false,'','Developer','isCPR',true]
      - BGType: ['Background Type',['light on dark','dark on light','other'],true,'Whether the animals are always lighter than the background (light on dark), always darker than the background (dark on light), or neither (other).','dark on light','','Developer','isCPR',true]
      - BGReadFcn: ['Background Read Function',string,true,"Function that reads background for a project movie. Signature: [bg,bgdev] = fcn(movfile,movifo)",'','','Developer','isCPR',true]
    - HistEq:
      - ['Histogram Equalization','',false,'Parameters related to normalization of the image intensity range. You should use histogram equalization if lighting of the animals varies across videos, e.g. if you have different lighting setups producing videos that differ in their brightness and contrast. Histogram equalization will adjust image intensities in each video so that the distributions of intensities (i.e. the histograms) match.','','','','isCPR']
      - Use: ['Enable',boolean,true,'Whether to use histogram equalization (CLAHE) to normalize image intensity. You should use histogram equalization if lighting of the animals varies across videos, e.g. if you have different lighting setups producing videos that differ in their brightness and contrast.',false,'','Beginner','isCPR',true]
    - MultiTarget:
      - ['Body Tracking','',false,"APT tracks multiple animals by relying on another piece of software, e.g. Ctrax, to track the body positions of each animal. Using the trajectories output by e.g. Ctrax, APT crops out regions centered around each tracked animal and runs part-tracking on these image crops. These parameters describe how image patches around individual animals are cropped out.",'','','','']
      - NeighborMask:
        - ['Mask Neighbors','',false,"When targets come in close proximity to each other, non-touching neighbors can be masked.",'','','','isCPR']
        - Use: ['Enable',boolean,true,"Use simple image processing to try to mask out other, non-touching targets. This requires Background Read Function above to be set properly.",false,'','Developer',['hasTrx', 'isCPR'],true]
        - SegmentMethod: ['Segmentation Method',['Conn. Comp','GMM-EM','Emp. PDF'],true,"Masking algorithm/approach.",'Conn. Comp','','Developer',['hasTrx','isCPR'],true]
        - FGThresh: ['Foreground Threshold',float,true,'Background-subtracted pixels above this threshold are considered foreground subject to masking.',4,'',Developer,['hasTrx','isCPR'],true]