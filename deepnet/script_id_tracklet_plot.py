info = [{}]
info[-1]['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/nochr_TrpA65F12_Unknown_RigB_20201212T163629_grone.trk'
info[-1]['mov_file'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629//movie.ufmf'
# info[-1]['mov_file'] = '/nearline/branson/from_tier2/fly_bubble/bubble_data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/movie.ufmf'
info[-1]['fix_error_trx'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/fixed_trx.mat'
info[-1]['ht_pts'] = [0,6]
info[-1]['ctrax'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/registered_trx.mat'
info[-1]['im_sz'] = [96,96]
info[-1]['n_animals'] = 10
info[-1]['rescale'] = 1
info[-1]['name'] = 'nochr_TrpA65F12_Unknown_RigB_20201212T163629'

info.append({})
info[-1]['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/nochr_TrpA65F12_Unknown_RigB_20201212T163629_grone_scale2.trk'
info[-1]['mov_file'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629//movie.ufmf'
# info[-1]['mov_file'] = '/nearline/branson/from_tier2/fly_bubble/bubble_data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/movie.ufmf'
info[-1]['fix_error_trx'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/fixed_trx.mat'
info[-1]['ht_pts'] = [0,6]
info[-1]['ctrax'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/registered_trx.mat'
info[-1]['im_sz'] = [96,96]
info[-1]['n_animals'] = 10
info[-1]['rescale'] = 0.5
info[-1]['name'] = 'nochr_TrpA65F12_Unknown_RigB_20201212T163629_scale2'

info.append({})
info[-1]['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/nochr_TrpA65F12_Unknown_RigB_20201212T163629_grone_nohardmine.trk'
info[-1]['mov_file'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629//movie.ufmf'
# info[-1]['mov_file'] = '/nearline/branson/from_tier2/fly_bubble/bubble_data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/movie.ufmf'
info[-1]['fix_error_trx'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/fixed_trx.mat'
info[-1]['ht_pts'] = [0,6]
info[-1]['ctrax'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/registered_trx.mat'
info[-1]['im_sz'] = [96,96]
info[-1]['n_animals'] = 10
info[-1]['rescale'] = 0.5
info[-1]['name'] = 'nochr_TrpA65F12_Unknown_RigB_20201212T163629_nohardmine'

curi = {}
curi['mov_file'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/movie.ufmf'
curi['fix_error_trx'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/fixedtrx_20230117T174500.mat'
curi['ht_pts'] = [0,6]
curi['ctrax'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/registered_trx.mat'
curi['im_sz'] = [96,96]
curi['n_animals'] = 10
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/nochr_TrpA65F12_Unknown_RigA_20201212T163531_grone.trk'
curi['rescale'] = 1
curi['name'] = 'nochr_TrpA65F12_Unknown_RigA_20201212T163531'
info.append(curi)


curi = {}
curi['mov_file'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/movie.ufmf'
curi['fix_error_trx'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/fixedtrx_20230117T174500.mat'
curi['ht_pts'] = [0,6]
curi['ctrax'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/registered_trx.mat'
curi['im_sz'] = [96,96]
curi['n_animals'] = 10
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/nochr_TrpA65F12_Unknown_RigA_20201212T163531_grone_scale2.trk'
curi['rescale'] = 0.5
curi['name'] = 'nochr_TrpA65F12_Unknown_RigA_20201212T163531_scale2'
info.append(curi)

curi = {}
curi['mov_file'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/movie.ufmf'
curi['fix_error_trx'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/fixedtrx_20230117T174500.mat'
curi['ht_pts'] = [0,6]
curi['ctrax'] = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigA_20201212T163531/registered_trx.mat'
curi['im_sz'] = [96,96]
curi['n_animals'] = 10
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/nochr_TrpA65F12_Unknown_RigA_20201212T163531_grone_nohardmine.trk'
curi['rescale'] = 0.5
curi['name'] = 'nochr_TrpA65F12_Unknown_RigA_20201212T163531_nohardmine'
info.append(curi)

curi = {}
curi['mov_file'] = '/groups/branson/home/robiea/Projects_data/Labeler_APT/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie.ufmf'
curi['ctrax'] = '/groups/branson/home/bransonk/tracking/code/APT/data/FlyBubble/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie/movie_JAABA/trx.mat'
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/cx_GMR_SS00030_CsChr_RigC_20150826T144616_grone.trk'
curi['fix_error_trx'] = '/groups/branson/bransonlab/mayank/apt_results/cx_GMR_SS00030_CsChr_RigC_20150826T144616_fix_error_GT.mat'
curi['ht_pts'] = [0,6]
curi['im_sz'] = [96,96]
curi['n_animals'] = 10
curi['rescale'] = 1
curi['name'] = 'cx_GMR_SS00030_CsChr_RigC_20150826T144616'
info.append(curi)

curi = {}
curi['mov_file'] = '/groups/branson/home/robiea/Projects_data/Labeler_APT/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie.ufmf'
curi['ctrax'] = '/groups/branson/home/bransonk/tracking/code/APT/data/FlyBubble/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie/movie_JAABA/trx.mat'
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/cx_GMR_SS00030_CsChr_RigC_20150826T144616_grone_scale2.trk'
curi['fix_error_trx'] = '/groups/branson/bransonlab/mayank/apt_results/cx_GMR_SS00030_CsChr_RigC_20150826T144616_fix_error_GT.mat'
curi['ht_pts'] = [0,6]
curi['im_sz'] = [96,96]
curi['n_animals'] = 10
curi['rescale'] = 0.5
curi['name'] = 'cx_GMR_SS00030_CsChr_RigC_20150826T144616_scale2'
info.append(curi)

curi = {}
curi['mov_file'] = '/groups/branson/home/robiea/Projects_data/Labeler_APT/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie.ufmf'
curi['ctrax'] = '/groups/branson/home/bransonk/tracking/code/APT/data/FlyBubble/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie/movie_JAABA/trx.mat'
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/cx_GMR_SS00030_CsChr_RigC_20150826T144616_grone_nohardmine.trk'
curi['fix_error_trx'] = '/groups/branson/bransonlab/mayank/apt_results/cx_GMR_SS00030_CsChr_RigC_20150826T144616_fix_error_GT.mat'
curi['ht_pts'] = [0,6]
curi['im_sz'] = [96,96]
curi['n_animals'] = 10
curi['rescale'] = 0.5
curi['name'] = 'cx_GMR_SS00030_CsChr_RigC_20150826T144616_nohardmine'
info.append(curi)


curi = {}
curi['mov_file'] = '/groups/branson/bransonlab/roian/apt_testing/files_for_working_with_apt/four_and_five_mice_recordings_210924/20210924_four_female_mice/20210924_four_female_mice_0.mjpg'
# curi['id_trk'] = '/groups/branson/bransonlab/mayank/apt_cache_2/unmarked_mice_inc/trks/20210924_four_female_mice_0_unmarkedMice_round7_trained.trk'
curi['id_trk'] = '/groups/branson/home/kabram/temp/ma_expts/roian/trks/20210924_four_female_mice_0_grone_crop_mask.trk'
curi['fix_error_trx'] = '/groups/branson/bransonlab/mayank/apt_results/20210924_four_female_mice_0_fix_error_GT.mat'
curi['ht_pts'] = [0,1]
curi['rescale'] = 1
curi['n_animals'] = 4
curi['im_sz'] = [268,268]
curi['name'] = '20210924_four_female_mice_0'

info.append(curi)

curi = {}
curi['mov_file'] = '/groups/branson/bransonlab/roian/apt_testing/files_for_working_with_apt/four_and_five_mice_recordings_210924/20210924_four_female_mice/20210924_four_female_mice_0.mjpg'
curi['id_trk'] = '/groups/branson/bransonlab/mayank/apt_cache_2/unmarked_mice_inc/trks/20210924_four_female_mice_0_unmarkedMice_rand_labels_4x_roi_nohardmine.trk'
curi['fix_error_trx'] = '/groups/branson/bransonlab/mayank/apt_results/20210924_four_female_mice_0_fix_error_GT.mat'
curi['ht_pts'] = [0,1]
curi['rescale'] = 1
curi['n_animals'] = 4
curi['im_sz'] = [268,268]
curi['name'] = '20210924_four_female_mice_0_nohardmine'

# this movie has interesting behavior at frame 82720, 105100. round7 does better than rand_4x
info.append(curi)

#
from poseConfig import conf
import TrkFile
from reuse import *
import link_trajectories as lnk
import movies

idx = 1

# pure_tracklet_old = info[idx]['id_trk'].replace('.trk','_tracklet.trk')
# pure_tracklet = info[idx]['id_trk'].replace('.trk','_temp_pure.trk')

# # redo pure tracklet linking in case parameters have changed
# if os.path.exists(pure_tracklet):
#     trk_p = TrkFile.Trk(pure_tracklet)
# else:
#     trk_p = TrkFile.Trk(pure_tracklet_old)
#     trk_p = lnk.link_pure(trk_p, conf)  # to get the threshold
#     trk_p.save(pure_tracklet, saveformat='tracklet')

pure_tracklet = info[idx]['id_trk'].replace('.trk','_tracklet.trk')
trk_p = TrkFile.Trk(pure_tracklet)

trk_i = TrkFile.Trk(info[idx]['id_trk'])

# create the conf
for k in trk_p.trkData['trkInfo']['params']:
    conf.__dict__[k] = trk_p.trkData['trkInfo']['params'][k]

conf.has_trx_file = False
conf.use_bbox_trx = False
conf.use_ht_trx = True
conf.img_dim = 3
conf.trx_align_theta = True
conf.link_id = True
# conf.ht_pts = (0,1)
conf.ht_pts = info[idx]['ht_pts']
conf.imsz = info[idx]['im_sz']

# this is from script_apt_expts
def get_trx_frame(trx,fr):
    # pts is n_trx x 2 x 2, where second dim has the head and tail points
    valid_trx = np.where( (trx['first_frames']<=fr) & (trx['end_frames']>fr) )[0]
    pts = np.ones([trx['n_trx'],2,2])*np.nan
    for vv in range(trx['n_trx']):
        if vv in valid_trx:
            fro = fr-int(trx['trx'][vv]['firstframe'][0,0])+1
            xx = trx['trx'][vv]['x'].flatten()[fro]-1
            yy = trx['trx'][vv]['y'].flatten()[fro]-1
            theta = trx['trx'][vv]['theta'].flatten()[fro]
            a = trx['trx'][vv]['a'].flatten()[fro]

            hh = np.array([xx+a*np.cos(theta)*2,yy+a*np.sin(theta)*2])
            tt = np.array([xx-a*np.cos(theta)*2,yy-a*np.sin(theta)*2])

            pts[vv,0,:] = hh
            pts[vv,1,:] = tt
    return pts



# Find the embeddings for tracklets of length >10
# First read the images

use_motion = False
motion_type = 'motion' if use_motion else 'no_motion'

id_wts = info[idx]['id_trk'].replace('.trk','_idwts.p')
mov_file = info[idx]['mov_file']

cap = movies.Movie(mov_file)
nfr = cap.get_n_frames()
cap.close()

trx_dict = apt.get_trx_info(pure_tracklet, conf, nfr,use_ht_pts=True)
trx = trx_dict['trx']

net = lnk.load_id_wts(id_wts)

net = net.eval()

# sample images for each tracklet and then find the embeddings for them
ss, ee = trk_p.get_startendframes()

min_len_select = 10

sel_tgt = np.where((ee - ss + 1) >=min_len_select)[0]
sel_ss = ss[sel_tgt]
sel_ee = ee[sel_tgt]

# Find the linking costs as done in id linking

import torch

scale = info[idx]['rescale']
conf.has_trx_file= False
pure_trx_dict = apt.get_trx_info(pure_tracklet,conf,nfr,use_ht_pts=True)
pure_trx = pure_trx_dict['trx']

dist_mat, pred_map_orig, all_data, preds = lnk.get_id_dist_xmat([trk_p],net,[mov_file],conf,[pure_trx],scale,min_len_select,True)
close_thresh, far_thresh = lnk.get_id_thresh(dist_mat,pred_map_orig,all_data)

params = lnk.get_default_params(conf)
maxcost_missed = lnk.estimate_maxcost_missed(trk_p, params)
maxcost = lnk.estimate_maxcost(trk_p, params)
# FInd the linkinking costs between the tracklets
st, en = trk_p.get_startendframes()
link_costs = lnk.get_link_costs(trk_p, st, en, params)

pred_map = pred_map_orig.copy()

# Find the type of links
cur_ss, cur_ee = trk_p.get_startendframes()
maxn = max(cur_ee)
cur_sel = np.array([ix for ix in range(len(pred_map)) if pred_map[ix, 0] == 0])
sel_tgt = pred_map[cur_sel, 1]
cur_dist_mat = dist_mat[cur_sel][:, cur_sel]
motion_grs, link_type,all_paths = lnk.group_tracklets_motion(cur_dist_mat, trk_p, link_costs, close_thresh, min_len_select)

# do id tracking to get the linking data

trk_p1 = trk_p.copy()
id_trk, link_data = lnk.link_trklet_id([trk_p],net,[mov_file],conf,[pure_trx],scale,min_len_select,True,link_method=motion_type)
trk_p = trk_p1
id_trk = id_trk[0]
link_type = link_data[0][0]
motion_grs = link_data[1]
try:
    gr_data = link_data[2]
    gv_len = link_data[3]
    xmat = link_data[4]
except:
    try:
        del gr_data,gv_len,xmat
    except:
        pass


# id_trk.save(info[idx]['id_trk'].replace('.trk','_temp.trk'),saveformat='tracklet')
# id_trx_dict = apt.get_trx_info(info[idx]['id_trk'].replace('.trk','_temp.trk'),conf,nfr,use_ht_pts=True)
# id_trx = id_trx_dict['trx']

id_trk = trk_i
id_trx_dict = apt.get_trx_info(info[idx]['id_trk'],conf,nfr,use_ht_pts=True)
id_trx = id_trx_dict['trx']


# Assign GT to each ID tracklet and pure tracklet

import scipy.optimize as opt

npure = trk_p.ntargets
gt_i = np.ones(npure)*np.nan
tt = trk_p
ss,ee = tt.get_startendframes()

nfr = max(ee)+1
conf.has_trx_file= True
gt_trx_dict = apt.get_trx_info(info[idx]['fix_error_trx'],conf,nfr,use_ht_pts=True)
conf.has_trx_file= False
gt_trx = gt_trx_dict['trx']

ngt = gt_trx_dict['n_trx']
ssi,eei = id_trk.get_startendframes()
id_gt = np.ones([id_trk.ntargets,nfr])*np.nan
gt_trk = np.ones([nfr,ngt,conf.n_classes,2])*np.nan
gt_pure_id = np.ones([nfr,id_trk.ntargets])*np.nan
multi_match = []
for ndx in range(nfr):
    idp = id_trk.getframe(ndx)[:,:,0].transpose([2,0,1])
    p = idp[:,info[idx]['ht_pts']]
    vv = np.where(~np.all(np.isnan(p[:,:,0]),axis=1))[0]
    g = get_trx_frame(gt_trx_dict,ndx)
    # Find the matches using hungarian algorithm

    dd = np.sum(np.linalg.norm(p[vv,None]-g[None],axis=(-1)),axis=-1)
    # dd[0] has match for p[0], dd[:,0] has match for g[0]
    sz = np.linalg.norm(g[:,0]-g[:,1],axis=-1).mean()
    dd_m = dd/sz
    idp1,idg = opt.linear_sum_assignment(dd_m)

    for npp,ng in zip(idp1,idg):

        if dd_m[npp,ng]>np.sqrt(2):
            print(f'Frame {ndx}, gt {ng} has large distance to pure tracklet {vv[npp]}: {dd_m[npp,ng]:.2f}')
            id_gt[vv[npp]][ndx-ss[vv[npp]]] = -1
            continue

        jx = np.partition(dd_m[npp],1)
        jy = np.partition(dd_m[:,ng],1)
        if (jx[1]/jx[0]>1.5) and (jy[1]/jy[0]>1.5):
            gt_trk[ndx,ng] = idp[vv[npp]]
        else:
            multi_match.append([ndx,vv[npp],ng,jx[1]/jx[0]])
        gt_pure_id[ndx,ng] = vv[npp]
        id_gt[vv[npp]][ndx-ssi[vv[npp]]] = ng

    if dd_m.shape[0]>ngt:
        extra = list(set(range(dd_m.shape[0]))-set(idp1))[0]
        id_gt[vv[extra]][ndx-ss[vv[extra]]] = -1

# For each pure tracklet, find the ID tracklet it belongs to and how it got linked

# First find all the pure tracklets that got matched by

pure_id = np.ones([trk_p.ntargets])*np.nan
pure_links = np.ones([trk_p.ntargets,2])*np.nan

try:
    for pp in all_paths:
        if len(pp)==0: continue
        pure_links[pp[:-1],1] = link_type[pp[0],0]
        pure_links[pp[1:],0] = link_type[pp[0],0]

    for gxx in gr_data:
        for _,gr in gxx:
            start = gr[np.argmin([ss[xx] for xx in gr])]
            end = gr[np.argmax([ee[xx] for xx in gr])]
            pure_links[start,0] = 4
            pure_links[end,1] = 4
except:
    pass
no_match = []
for ndx in range(trk_p.ntargets):
    ff = id_trk.getframe(range(ss[ndx],ee[ndx]+1))
    dd = np.nanmean(np.abs(ff-trk_p.pTrk.data[ndx][...,None]),axis=(0,1,2))
    if len(np.where(dd<0.01)[0]) in [0,2]:
        print(f'Pure tracklet {ndx} has no match or has multiple matches')
        no_match.append(ndx)
        cur_id = np.nan
        if ndx in sel_tgt:
            pure_id[ndx] = -1

    else:
        cur_id = np.where(dd<0.01)[0][0]
        # print(f'Pure tracklet {ndx} has match {cur_id}')
        pure_id[ndx] = cur_id
        if np.isnan(pure_links[ndx,0]):
            pure_links[ndx,0] = 5
            pure_links[ndx,1] = 5

    if ss[ndx]==0:
        pure_links[ndx,0] = 0
    if ee[ndx]==nfr-1:
        pure_links[ndx,1] = 0

ll1 = ee-ss+1
ww = np.array(list(zip(*np.where(np.isnan(pure_links)))))
# ll1[np.unique(ww[:,0])]

from matplotlib.pyplot import colormaps
from matplotlib.collections import PatchCollection
from matplotlib.patches import Rectangle


import matplotlib.colors as mcolors

# Function to increase saturation
def increase_saturation(color, factor=1.5):
    color = mcolors.to_rgb(color)
    hsv = mcolors.rgb_to_hsv(color)
    hsv[1] = np.clip(hsv[1] * factor, 0, 1)
    return mcolors.hsv_to_rgb(hsv)

def increase_value(color, factor=1.5):
    color = mcolors.to_rgb(color)
    hsv = mcolors.rgb_to_hsv(color)
    hsv[2] = np.clip(hsv[2] * factor, 0, 1)
    return mcolors.hsv_to_rgb(hsv)

# for ndx in range(trk_p.ntargets):
#     cci = pure_id[ndx]
#     if cci<0:
#         continue
#     plt.plot([ee[ndx],ee[ndx]],[cci-0.5,cci-0.05],'k',linewidth=0.5,alpha=0.25)
#
# for ndx in range(id_trk.ntargets):
#     plt.plot(gt_pure_id[:,ndx],label=f'GT tracklet {ndx}')

##

gid_cmap = 'tab10'
if gid_cmap == 'tab10':

    colors = pt.get_cmap(10,gid_cmap)[[4,0,8,7,2,9,3,1,6,5]]
    for xx in range(trk_i.ntargets//10-1):
        colors = np.concatenate([colors,pt.get_cmap(10,gid_cmap)])
    colors = np.concatenate([colors,pt.get_cmap(trk_i.ntargets%10,gid_cmap)])
else:
    colors = pt.get_cmap(id_trk.ntargets,gid_cmap)
colors = np.array([increase_value(xx) for xx in colors])
colors = np.array([increase_saturation(xx) for xx in colors])


rectangles = []
rcolors = []
ecolors = []
zorder = []
f,ax = plt.subplots(1,1,figsize=(5,2.5))

if idx==1:
    # plot_ids = np.array([0,1,2,3,4,5,6,7,8,9])
    plot_gts = np.array([5,0,6,1,4,7,3,2,8,9])
else:
    # plot_ids = np.arange(trk_i.ntargets)
    plot_gts = np.arange(ngt)

for ndx in range(trk_p.ntargets):
    cci = pure_id[ndx]
    if cci<0 or np.isnan(cci):
        continue
    cur_gt = id_gt[int(cci)][ss[ndx]:ee[ndx]+1]
    brs = np.where(cur_gt[1:]!=cur_gt[:-1])[0]
    brs = np.concatenate([[0],brs+1,[ee[ndx]-ss[ndx]+1]])
    for br in range(len(brs)-1):
        if np.isnan(cur_gt[brs[br]]):
            continue
        rectangles.append(Rectangle((ss[ndx]+brs[br]-0.5,plot_gts[int(cur_gt[brs[br]])]-0.5),brs[br+1]-brs[br],1-0.01))
        rcolors.append(colors[int(cci)])
        ecolors.append([0,0,0,0])
        zorder.append(int(cur_gt[brs[br]]))
    # plt.plot([ss[ndx],ss[ndx]],[cur_gt[0]-0.5,cur_gt[0]],'k',linewidth=0.5,alpha=0.25)
    # if len(np.unique(cur_gt[~np.isnan(cur_gt)])==1):
    #     rectangles.append(Rectangle((ss[ndx]-0.5,cur_gt[brs[br]]-0.5),ll1[ndx],1))
    #     rcolors.append([0,0,0,0])
    #     ecolors.append([0,0,0,0.5])
    # else:
    #     rectangles.append(Rectangle((ss[ndx]-0.5,cur_gt[0]-0.5),0,1))
    #     rcolors.append([0,0,0,0])
    #     ecolors.append([0,0,0,0.5])
    #     rectangles.append(Rectangle((ee[ndx]-0.5,cur_gt[-1]-0.5),0,1))
    #     rcolors.append([0,0,0,0])
    #     ecolors.append([0,0,0,0.5])


collection = PatchCollection(rectangles,facecolor=rcolors,edgecolor=ecolors,linewidth=0.5,antialiased=False)
ax.add_collection(collection)
for ndx in range(trk_p.ntargets):
    cci = pure_id[ndx]
    if cci<0 or np.isnan(cci):
        continue
    cur_gt = id_gt[int(cci)][ss[ndx]:ee[ndx]+1]
    # plt.plot([ss[ndx], ss[ndx]], [cur_gt[0] - 0.5 + 0.02, cur_gt[0] - 0.2], 'k', linewidth=0.5, alpha=0.25,zorder=10)

for ndx in range(ngt):
    acc = np.max(np.sum(id_gt==ndx,axis=1))/id_gt.shape[1]
    plt.text(nfr/2,plot_gts[ndx],f'{acc:.2f}',ha='center',va='center',zorder=100,alpha=0.7)

plt.xlim([-0.5,nfr-0.5])
plt.ylim([-0.5,ngt-0.5])
# plt.gca().invert_yaxis()
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

plt.xlabel('Frame number')
plt.ylabel('Labeled ID')

if idx ==1: # plot rectangles to show the parts that are shown later
    fr_s=43000
    fr_e=44000
    x_s = -0.5
    x_e = 2.5
    plt.plot([fr_s,fr_s,fr_e,fr_e,fr_s],[x_s,x_e,x_e,x_s,x_s],'k',linewidth=1)

    fr_s=34800
    fr_e=35300
    x_s = 4.5
    x_e = 7.5
    plt.plot([fr_s,fr_s,fr_e,fr_e,fr_s],[x_s,x_e,x_e,x_s,x_s],'k',linewidth=1)


f.tight_layout()

#
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_gt_id_map.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_gt_id_map.svg',dpi='figure')

# show id clusters
import scipy

sel_ids_show = list(range(info[idx]['n_animals']))
sel_id = np.array([int(pure_id[xx]) for xx in sel_tgt])
ord = []
id_count = np.sum(~np.isnan(id_gt),axis=1)
id2gt = np.array([scipy.stats.mode(xx[~np.isnan(xx)]) for xx in id_gt])[...,0]
nc = id2gt[:,1]
id2gt = id2gt[:,0].astype('int')
breaks = []
gt_breaks = []
aa,bb = id_trk.get_startendframes()
for indx in sel_ids_show:
    cur_idd = np.where(id2gt==indx)[0]
    for ndx in cur_idd:
        if bb[ndx]-aa[ndx]<nfr/20:
            continue
        cur_id = np.where(sel_id==ndx)[0]
        cur_id = cur_id[np.argsort([ss[sel_tgt[xx]] for xx in cur_id])]
        ord.extend(cur_id.tolist())
        breaks.append(len(ord))
    gt_breaks.append(len(ord))

cmat = dist_mat[ord][:,ord]

rectangles = []
colormap = 'coolwarm'

colors1 = colormaps.get_cmap(colormap)
rcolors = []
cur_col = 0
breaks1 = []
gt_breaks1 = []
trk_brks = []
for ixx,ix in enumerate(ord):
    szx = ee[sel_tgt[ix]]-ss[sel_tgt[ix]]+1
    cur_row = 0
    for iyy,iy in enumerate(ord):
        szy = ee[sel_tgt[iy]]-ss[sel_tgt[iy]]+1
        rectangles.append(Rectangle( (cur_col,cur_row),szx,szy))
        rcolors.append(colors1(np.clip(cmat[ixx,iyy],0,2)/2))
        cur_row += szy
    cur_col += szx
    trk_brks.append(cur_col)
    if ixx+1 in breaks:
        breaks1.append(cur_col)
    if ixx+1 in gt_breaks:
        gt_breaks1.append(cur_col)


f,ax = plt.subplots(1,1,figsize=(6.2,5))
ax.imshow(np.array([[0,2]]),cmap=colormap)
plt.colorbar(ax.images[0],ax=ax)
collection = PatchCollection(rectangles,facecolor=rcolors)
ax.add_collection(collection)
# ax.set_xlim([0,cur_col])
# ax.set_ylim([0,cur_row])
plt.hlines(trk_brks,0,nfr/5,colors='w',linewidth=0.5,alpha=0.5)
plt.vlines(trk_brks,0,nfr/5,colors='w',linewidth=0.5,alpha=0.5)
# ax.vlines(trk_brks,0,cur_row,colors='w',alpha=0.1,linewidth=0.5)
# ax.hlines(trk_brks,0,cur_row,colors='w',alpha=0.1,linewidth=0.5)
ax.vlines(breaks1[:-1],0,cur_row,colors='r',alpha=0.3)
ax.hlines(breaks1[:-1],0,cur_col,colors='r',alpha=0.3)
ax.vlines(gt_breaks1[:-1],0,cur_row,colors='k',alpha=0.5)
ax.hlines(gt_breaks1[:-1],0,cur_col,colors='k',alpha=0.5)
gtb1 = [0,]+gt_breaks1
ticks = [(gtb1[xx]+gtb1[xx+1])/2 for xx in range(len(gtb1)-1)]
ax.set_xticks([])
# ax.set_xticklabels(range(len(gt_breaks)))
ax.set_yticks([])
# ax.set_yticklabels(range(len(gt_breaks)))
# ax.vlines(ticks,cur_col,cur_col+nfr/10,colors='k',linewidth=1)
# ax.hlines(ticks,0,-nfr/10,colors='k',linewidth=1)
for idxx,tt in enumerate(ticks):
    plt.text(tt,cur_col+nfr/5*1,f'ID {int(idxx+1)}',ha='center',va='center')
    plt.text(-nfr/5*2,tt,f'ID {int(idxx+1)}',ha='center',va='center')

plt.axis('equal')
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)
plt.gca().spines['left'].set_visible(False)
plt.gca().spines['bottom'].set_visible(False)

# plt.axis('off')
plt.title('Tracklet Distance')
plt.xlabel(f'Tracklets grouped by label ID')
# plt.gca().invert_yaxis()
f.tight_layout()

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_cluster.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_cluster.svg')


f = plt.figure()
plt.imshow(cmat,cmap=colormap,vmin=0,vmax=2)
plt.colorbar()
plt.title('Tracklet Distance')
plt.xlabel(f'Tracklets grouped by label ID')
f.tight_layout()
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_cluster_tracklet.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_cluster_tracklet.svg')

f = plt.figure(figsize=(4,3))
tlen = ee-ss+1
bins = np.logspace(np.log10(min(tlen)),np.log10(max(tlen)),20)
plt.hist(ee-ss+1,bins)
#set yaxis to log
plt.yscale('log')
plt.xscale('log')
plt.xlabel('Tracklet length',fontsize=10)
plt.ylabel('Number of tracklets',fontsize=10)
plt.title('Tracklet length distribution',fontsize=12)
plt.xticks(fontsize=8)
plt.yticks(fontsize=8)
f.tight_layout()
out_f = f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_tracklet_distribution'
plt.savefig(f'{out_f}.png')
plt.savefig(f'{out_f}.svg')

## show trajectories for training

fr_s = 33960
fr_e = 34075
offset = 10
qq = trk_p.getframe(range(fr_s,fr_e+1))
qqb = trk_p.getframe(range(fr_s-offset,fr_s))
qqa = trk_p.getframe(range(fr_e+1,fr_e+offset+1))
ss,ee = trk_p.get_startendframes()
vv = np.any(~np.isnan(qq[0,0]),axis=0) & ((ss>=fr_s)|(ee<=fr_e)) #& (ee-ss>10)
vv =np.where(vv)[0]
qq = qq[...,vv]
qqb = qqb[...,vv]
qqa = qqa[...,vv]
apts = info[idx]['ht_pts']
qj = np.mean(qq[apts],axis=0)
qjb = np.mean(qqb[apts],axis=0)
qja = np.mean(qqa[apts],axis=0)
f = plt.figure()

ax = f.add_axes([0.1,0.55,0.4,0.4]) # for the trajectories
ax1 = f.add_axes([0.05, 0.01, 0.4, 0.4]) # sampled images
ax2 = f.add_axes([0.55,0.55,0.4,0.4])  # for the initial embeddings
ax3 = f.add_axes([0.55,0.05,0.4,0.4]) # for the final embeddings

hh = ax.plot(range(fr_s,fr_e+1),qj[1])#+qj[0]/10)

small_t = np.where((ee-ss+1)[vv]<10)[0]
for xx in small_t:
    hh[xx].set_alpha(0.5)
    hh[xx].set_linewidth(0.5)

sel_trk = 296

all_ii = []
for ix,ndx in enumerate(vv):
    ax.plot(range(fr_s-offset,fr_s),qjb[1,:,ix],c=hh[ix].get_color(),linewidth=0.5,linestyle='--')
    ax.plot(range(fr_e+1,fr_e+offset+1),qja[1,:,ix],c=hh[ix].get_color(),linewidth=0.5,linestyle='--')
    if ndx not in sel_tgt:
        continue
    sndx = np.where(sel_tgt==ndx)[0][0]
    curd = all_data[0][0][sndx]
    curf = np.array(curd[-1])[:,0]
    curf = curf[curf>=fr_s]
    curf = curf[curf<=fr_e]
    ax.scatter(curf,qj[1,curf-fr_s,ix],c=hh[ix].get_color(),s=10)

    all_ii.append(curd[0])

all_ii = np.array(all_ii)
w,h = all_ii.shape[2:4]
ntrj = all_ii.shape[0]
ax.set_xlabel('Frame number')
ax.set_ylabel('Y position')
ax.set_title('Detected Tracklets')
ax.set_xticks(ax.get_xticks()[::2])


n_show = 4
all_ii_o = all_ii.copy()
all_ii = all_ii[:,:n_show]
all_ii = all_ii.transpose([1, 2, 0, 3,4])
all_ii = all_ii.reshape([n_show * curd[0].shape[1], ntrj * curd[0].shape[2],curd[0].shape[3]])
ax1.imshow(all_ii.astype('uint8'))
count = 0
for ix,ndx in enumerate(vv):
    if ndx not in sel_tgt:
        continue
    # ax1.plot([count * w, count * w - 3.5, (count + 1) * w - 3.5, (count + 1) * w - 3.5, count * w],
    #          [-0.5, all_ii.shape[0] - 0.5, all_ii.shape[0] - 0.5, -.5, -.5], c=hh[ix].get_color(), linewidth=2)
    # for jx in range(n_show-1):
    #     ax1.plot( [count*w,(count+1)*w],[(jx+1)*h,(jx+1)*h], c=hh[ix].get_color(),linewidth=2)
    ax1.plot( [count*w,(count+1)*w],[(n_show)*h-5,(n_show)*h-5], c=hh[ix].get_color(),linewidth=4)
    ax1.plot( [count*w,(count+1)*w],[2,2], c=hh[ix].get_color(),linewidth=4)

    count = count+1

ax1.axis('off')
ax1.set_xlim([0,all_ii.shape[1]])
ax1.set_ylim([all_ii.shape[0],0])
ax1.set_title('Sampled Images')

torch.manual_seed(60)
net_init = lnk.get_id_net()
net_init = net_init.eval()
net_init = net_init.to('cuda')
pred_init = lnk.tracklet_pred([all_ii_o.reshape([-1,w,h,3])],net_init,conf,scale)
pred_final = lnk.tracklet_pred([all_ii_o.reshape([-1,w,h,3])],net,conf,scale)

from sklearn.manifold import TSNE
pred_init_t = TSNE(n_components=2,random_state=60).fit_transform(pred_init[0])
pred_init_t = pred_init_t.reshape([ntrj,all_ii_o.shape[1],-1])
pred_final_t = TSNE(n_components=2,random_state=60).fit_transform(pred_final[0])
pred_final_t = pred_final_t.reshape([ntrj,all_ii_o.shape[1],-1])

count = 0
for ix,ndx in enumerate(vv):
    if ndx not in sel_tgt:
        continue
    ax2.scatter(pred_init_t[count,:,0],pred_init_t[count,:,1],c=hh[ix].get_color(),s=10)
    ax3.scatter(pred_final_t[count,:,0],pred_final_t[count,:,1],c=hh[ix].get_color(),s=10)
    count = count+1

ax2.set_yticks([])
ax2.set_xticks([])
ax2.axis('equal')
ax2.set_title('Initial Embeddings')
ax3.set_yticks([])
ax3.set_xticks([])
ax3.axis('equal')
ax3.set_title('Final Embeddings')
f.savefig(f'/groups/branson/home/kabram/temp/id_training.png')
f.savefig(f'/groups/branson/home/kabram/temp/id_training.svg')

##
f = plt.figure(figsize=(4,4))
ax = f.add_axes([0.1,0.1,0.8,0.8])
s_sel = ss[sel_trk]
e_sel = ee[sel_trk]
np.random.seed(40)
count1 = 0
count2 = 0
for ndx in np.random.permutation(vv):
    i = np.where(vv==ndx)[0][0]
    if ndx not in sel_tgt:
        continue
    if ndx==sel_trk:
        center = [0,0]
        sz = 0.3
    else:
        if ((ee[ndx] > s_sel) & (ss[ndx] < e_sel)):
            center = [1,(count1-1)/2]
            count1 = count1+1
        else:
            center = [2,(count2-1)/2]
            count2 = count2+1
        # center = [np.sin(count/6*2*np.pi),np.cos(count/6*2*np.pi)]
        # count = count+1
        sz = 0.2
    center = np.array(center)
    pts = (np.random.rand(25,2)-0.5)*sz*2+center
    plt.scatter(pts[:,0],pts[:,1],c=hh[i].get_color(),s=10)
    if ndx==sel_trk:
        dd = np.linalg.norm(pts-center,axis=-1)
        order = np.argsort(dd)[::-1]
        ax.annotate('', xy=pts[order[-1]], xytext=pts[order[1]],arrowprops=dict(color='green', arrowstyle="<->" ,linewidth=1))
        ax.annotate('', xy=pts[order[-1]], xytext=pts[order[2]],arrowprops=dict(color='green', arrowstyle="<->" ,linewidth=1))
        ax.annotate('', xy=pts[order[-1]], xytext=pts[order[3]],arrowprops=dict(color='green', arrowstyle="<->" ,linewidth=1))
        ax.annotate('', xy=pts[order[-1]], xytext=pts[order[4]],arrowprops=dict(color='green', arrowstyle="<->" ,linewidth=1))

    else:
        if ((ee[ndx]>s_sel)&(ss[ndx]<e_sel)):
            ax.annotate('', xy=center/3, xytext=3/4*center,
                        arrowprops=dict(color='red', arrowstyle="<->", linewidth=1))


ax.text(1,0.8,'Overlapping',ha='center')
ax.text(2,0.8,'Non-overlapping',ha='center')
ax.axis('off')
f.tight_layout()
f.savefig(f'/groups/branson/home/kabram/temp/IDTraining_overlap.png')

## show example of ID Tracking working on difficult cases

def shift_line_segment(p1, p2, distance):
    # Calculate the slope of the line segment
    dx = p2[0] - p1[0]
    dy = p2[1] - p1[1]

    # Calculate the perpendicular slope
    perp_slope = np.array([-dy, dx])

    # Normalize the perpendicular slope to get the unit vector
    perp_unit_vector = perp_slope / np.linalg.norm(perp_slope)

    # Shift the points by the specified distance
    shift_vector = perp_unit_vector * distance
    p1_shifted = p1 + shift_vector
    p2_shifted = p2 + shift_vector

    return np.array([p1_shifted, p2_shifted])


if idx==1:

    intv=0
    if intv==0:
        fr_s = 43100
        # fr_s = 43000
        fr_e = 44000
        sel_id = [1,8,4]
        gt_id = [3,7,1] # what are the gt that correspond to the predicted ids
        sel_frs = [43100,43500,43800,43850,43910]
        # sel_frs = np.arange(43000,44001,200)
    elif intv==1: # has the same flies as above, so not useful
        fr_s = 10500
        fr_e = 11500
        sel_id = [4,1,8]
        gt_id = [0,3,7]
        sel_frs = np.arange(fr_s,fr_e+1,200)
    elif intv==2:
        fr_s = 34800
        fr_e = 35300
        sel_id  = [2,6,5]
        gt_id = [5,0,2]
        sel_frs = np.arange(fr_s, fr_e + 1, 100)
    tr_len = 200
    bsz_x = 90
    bsz_y = 90
    nr = 1
    nc = len(sel_frs)
    text_y= 10
    lw= 2
    gt_matches = [6,4,5,1,0,2,7,8,3,9]
elif idx == 4:
    #intervals: 8850-8951, 8951-9400, 9400-9600
    intv = 0
    lw = 2
    if intv ==0:
        fr_s= 8850
        fr_e = 8951
        sel_id = [1,6,2,8,0]#,0,7,9,3,8]
        gt_id = [6,2,9,7,5]#,5,1,4,3,7]
        sel_frs = [8850,8875,8900,8925,8950]
        tr_len = 200
        bsz_x = 120
        bsy_y = 120
        nr = 1
        nc = 5
        text_y = 10

    elif intv == 1:
        fr_s = 8950
        fr_e = 9401
        sel_id = [1,2,0,6,7,9,3,8]
        gt_id = [6,9,5,2,1,4,3,7]
        sel_frs = np.arange(fr_s,fr_e+1,50)
        tr_len = 200
        bsz_x = 240
        bsz_y = 100
        nr = 2
        nc = 5
        text_y = 10#2*bsz_y-30

    elif intv == 2:
        fr_s = 9400
        fr_e = 9601
        sel_id = [1,6,2,0,7,9,3,8]
        gt_id = [6,2,9,5,1,4,3,7]
        sel_frs = np.arange(fr_s,fr_e+1,50)
        tr_len = 200
        bsz_x = 220
        bsz_y = 110
        nr = 1
        nc = 5
        text_y = 2*bsz_y-30
    else:

        fr_s= 8850
        fr_e = 9651
        sel_id = [1,2,6,0,7,9,3,8]
        gt_id = [6,9,2,5,1,4,3,7]
        sel_frs = np.arange(fr_s,fr_e,40)
        tr_len = 200
        bsz_x = 280
        bsz_y = 125
        nr = 3
        nc = 7
        text_y = 2*bsz_y-30

pp = trk_i.getframe(range(fr_s,fr_e+1))

gg = []
for ndx in range(fr_s,fr_e+1):
    gg.append(get_trx_frame(gt_trx_dict,ndx))
gg = np.array(gg)

# colors = pt.get_cmap(id_trk.ntargets,gid_cmap)
# colors = np.array([increase_value(xx,1.8) for xx in colors])

bcenter = np.nanmean(pp[info[idx]['ht_pts']][...,sel_id],axis=(0,2,3)).astype('int')
bcenter = np.maximum(bcenter,[bsz_x,bsz_y])
ims = []
cap = movies.Movie(info[idx]['mov_file'])
for fr in sel_frs:
    im = cap.get_frame(fr)[0]
    im = im[bcenter[1]-bsz_y:bcenter[1]+bsz_y,bcenter[0]-bsz_x:bcenter[0]+bsz_x]
    ims.append(im)
ims = np.array(ims)

from matplotlib import patches

f,ax = plt.subplots(nr,nc,figsize=(nc*1.25*bsz_x/bsz_y,nr*1.25),sharex='all',sharey='all')
ax = ax.flatten()
skel = np.array(conf.op_affinity_graph)
apts = info[idx]['ht_pts']
for i in range(ims.shape[0]):
    ax[i].imshow(ims[i],cmap='gray')
    ax[i].axis('off')
    ax[i].text(ims.shape[2]/2,text_y,f'Frame {sel_frs[i]}',ha='center',va='center',fontsize=8)
    for curp in range(ngt): #len(sel_id)):
        spts = pp[apts,...,sel_frs[i]-fr_s,curp]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        pc = spts
        center = np.nanmean(pc,axis=0)
        major_axis_len = np.linalg.norm(pc[0]-pc[1])
        minor_axis_len = 20
        angle = np.degrees(np.arctan2(pc[1,1] - pc[0,1], pc[1,0] - pc[0,0]))

        ellipse = patches.Ellipse(center, major_axis_len, minor_axis_len, angle, edgecolor=colors[curp], facecolor='none',linewidth=1,zorder=0)
        ax[i].add_patch(ellipse)

        # ax[i].plot(spts[:,0],spts[:,1],color=colors[sel_id[curp]],linewidth=lw)
        gpts = gg[sel_frs[i]-fr_s][curp]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        # gpts = shift_line_segment(gpts[0],gpts[1],4)

        ax[i].plot(gpts[:,0],gpts[:,1],color=colors[gt_matches[curp]],linewidth=1)#,linestyle=(0,(1,1)))
        st = max(0,sel_frs[i]-fr_s-tr_len)
        en = min(fr_e-fr_s,sel_frs[i]-fr_s+tr_len)
        # gtrj = gg[st:en,gt_id[curp]]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        # gtrj = gtrj.mean(axis=1)
        # ax[i].plot(gtrj[:,0],gtrj[:,1],color=colors[sel_id[curp]],linewidth=0.5)

ax[0].set_xlim([0,ims.shape[2]])
ax[0].set_ylim([ims.shape[1],0])
f.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.02, hspace=0.02)

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_both.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_both.svg')

##
f,ax = plt.subplots(nr,nc,figsize=(nc*1.25*bsz_x/bsz_y,nr*1.25),sharex='all',sharey='all')
ax = ax.flatten()
skel = np.array(conf.op_affinity_graph)
apts = info[idx]['ht_pts']
for i in range(ims.shape[0]):
    ax[i].imshow(ims[i],cmap='gray')
    ax[i].axis('off')
    # ax[i].text(ims.shape[2]/2,text_y,f'Frame {sel_frs[i]}',ha='center',va='center',fontsize=8)
    for curp in range(ngt): #len(sel_id)):
        spts = pp[apts,...,sel_frs[i]-fr_s,curp]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        pc = spts
        center = np.nanmean(pc,axis=0)
        major_axis_len = np.linalg.norm(pc[0]-pc[1])
        minor_axis_len = 20
        angle = np.degrees(np.arctan2(pc[1,1] - pc[0,1], pc[1,0] - pc[0,0]))
        fc = 'none'
        if np.isnan(center).any():
            center = [ims[i].shape[1]/2,ims[i].shape[0]/10*9]
            major_axis_len = 10
            minor_axis_len = 10
            angle = 0
            ax[i].text(ims[i].shape[1]/4,ims[i].shape[0]/10*9,f'Missing:',ha='center',va='center',fontsize=8)
            fc = colors[curp]

        ellipse = patches.Ellipse(center, major_axis_len, minor_axis_len, angle, edgecolor=colors[curp], facecolor=fc,linewidth=1,zorder=0)
        ax[i].add_patch(ellipse)

        # ax[i].plot(spts[:,0],spts[:,1],color=colors[sel_id[curp]],linewidth=lw)
        # gpts = gg[sel_frs[i]-fr_s][gt_id[curp]]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        # gpts = shift_line_segment(gpts[0],gpts[1],4)
        #
        # ax[i].plot(gpts[:,0],gpts[:,1],color=colors[sel_id[curp]],linewidth=lw,linestyle=(0,(1,1)))
        # st = max(0,sel_frs[i]-fr_s-tr_len)
        # en = min(fr_e-fr_s,sel_frs[i]-fr_s+tr_len)
        # gtrj = gg[st:en,gt_id[curp]]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        # gtrj = gtrj.mean(axis=1)
        # ax[i].plot(gtrj[:,0],gtrj[:,1],color=colors[sel_id[curp]],linewidth=0.5)

ax[0].set_xlim([0,ims.shape[2]])
ax[0].set_ylim([ims.shape[1],0])
f.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.02, hspace=0.02)

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_pred.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_pred.svg')
##
f,ax = plt.subplots(nr,nc,figsize=(nc*1.25*bsz_x/bsz_y,nr*1.25),sharex='all',sharey='all')
ax = ax.flatten()
skel = np.array(conf.op_affinity_graph)
apts = info[idx]['ht_pts']
for i in range(ims.shape[0]):
    ax[i].imshow(ims[i],cmap='gray')
    ax[i].axis('off')
    ax[i].text(ims.shape[2]/2,text_y,f'Frame {sel_frs[i]}',ha='center',va='center',fontsize=8)
    for curp in range(ngt):
        # spts = pp[apts,...,sel_frs[i]-fr_s,curp]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        gpts = gg[sel_frs[i]-fr_s][curp]-bcenter[None]+np.array([bsz_x,bsz_y])[None]

        pc = gpts
        center = np.nanmean(pc,axis=0)
        major_axis_len = np.linalg.norm(pc[0]-pc[1])
        minor_axis_len = 20
        angle = np.degrees(np.arctan2(pc[1,1] - pc[0,1], pc[1,0] - pc[0,0]))

        ellipse = patches.Ellipse(center, major_axis_len, minor_axis_len, angle, edgecolor=colors[gt_matches[curp]], facecolor='none',linewidth=1,zorder=0)
        ax[i].add_patch(ellipse)

        # ax[i].plot(spts[:,0],spts[:,1],color=colors[sel_id[curp]],linewidth=lw)
        # gpts = gg[sel_frs[i]-fr_s][gt_id[curp]]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        # gpts = shift_line_segment(gpts[0],gpts[1],4)
        #
        # ax[i].plot(gpts[:,0],gpts[:,1],color=colors[sel_id[curp]],linewidth=lw,linestyle=(0,(1,1)))
        # st = max(0,sel_frs[i]-fr_s-tr_len)
        # en = min(fr_e-fr_s,sel_frs[i]-fr_s+tr_len)
        # gtrj = gg[st:en,gt_id[curp]]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
        # gtrj = gtrj.mean(axis=1)
        # ax[i].plot(gtrj[:,0],gtrj[:,1],color=colors[sel_id[curp]],linewidth=0.5)

ax[0].set_xlim([0,ims.shape[2]])
ax[0].set_ylim([ims.shape[1],0])
f.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.02, hspace=0.02)

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_gt.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_gt.svg')

#
# show the GT and predicted tracjectories
f,ax = plt.subplots(1,1,figsize=(1.25,1.25),sharex='all',sharey='all')
plt.axis('off')
plt.axis('equal')
skel = np.array(conf.op_affinity_graph)
apts = info[idx]['ht_pts']
st = 0
en = fr_e-fr_s
gtrj = gg[st:en,:]-bcenter[None]+np.array([bsz_x,bsz_y])[None]
gtrj = gtrj.mean(axis=2)
for ndx in range(gtrj.shape[1]):
    ax.plot(gtrj[:,ndx,0],gtrj[:,ndx,1],color=colors[gt_matches[ndx]],linewidth=0.5)
    for sfr_ in sel_frs:
        curss = min(fr_e-fr_s-1,sfr_-fr_s)
        ax.scatter(gtrj[curss,ndx,0],gtrj[curss,ndx,1],color=colors[gt_matches[ndx]],s=5)

ax.set_xlim([0,ims.shape[2]])
ax.set_ylim([ims.shape[1],0])
f.set_facecolor('black')
# f.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.02, hspace=0.02)

#
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_gt_traj.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_gt_traj.svg')

f,ax = plt.subplots(1,1,figsize=(1.25,1.25),sharex='all',sharey='all')
plt.axis('off')
plt.axis('equal')
skel = np.array(conf.op_affinity_graph)
apts = info[idx]['ht_pts']
st = 0
en = fr_e-fr_s
spts = pp[apts, ...] - bcenter[None,:,None,None] + np.array([bsz_x, bsz_y])[None,:,None,None]
center = np.nanmean(spts, axis=0)

for ndx in range(gtrj.shape[1]):
    ax.plot(center[0,:,ndx],center[1,:,ndx],color=colors[ndx],linewidth=0.5)
    for sfr_ in sel_frs:
        curss = min(fr_e-fr_s-1,sfr_-fr_s)
        ax.scatter(center[0,curss,ndx],center[1,curss,ndx],color=colors[ndx],s=5)

ax.set_xlim([0,ims.shape[2]])
ax.set_ylim([ims.shape[1],0])
f.set_facecolor('black')
# f.subplots_adjust(left=0.01, right=0.99, top=0.99, bottom=0.01, wspace=0.02, hspace=0.02)

#
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_pred_traj.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}_pred_traj.svg')
##
#
# do the gt id plot but only for selected gt ids

rectangles = []
rcolors = []
ecolors = []
zorder = []
# gid_cmap = 'tab20'
# colors = pt.get_cmap(id_trk.ntargets,gid_cmap)
# colors = np.array([increase_value(xx) for xx in colors])
f,ax = plt.subplots(1,1,figsize=(5,2.5))
y_sz = np.array([x in gt_id for x in range(ngt)])
# y_sz = np.array([True for x in range(ngt)])
y_off = np.cumsum(y_sz)-1
for ndx in range(trk_p.ntargets):
    pmap_ndx = np.where(link_data[2][:,1]==ndx)[0]
    if len(pmap_ndx)<1:
        continue
    motion_gr_ndx = [xx for xx in range(len(motion_grs)) if pmap_ndx in motion_grs[xx]]
    if len(motion_gr_ndx)<1:
        continue
    cci = motion_gr_ndx[0]
    cur_gt = id_gt[int(cci)][ss[ndx]:ee[ndx]+1]
    brs = np.where(cur_gt[1:]!=cur_gt[:-1])[0]
    brs = np.concatenate([[0],brs+1,[ee[ndx]-ss[ndx]+1]])
    for br in range(len(brs)-1):
        if np.isnan(cur_gt[brs[br]]):
            continue
        rectangles.append(Rectangle((ss[ndx]+brs[br]-0.5,y_off[int(cur_gt[brs[br]])]-0.5),brs[br+1]-brs[br],y_sz[int(cur_gt[brs[br]])]))
        rcolors.append(colors[int(cci)])
        ecolors.append([0,0,0,0])
        zorder.append(int(cur_gt[brs[br]]))


collection = PatchCollection(rectangles,facecolor=rcolors,edgecolor=ecolors,linewidth=0.5,antialiased=False)
ax.add_collection(collection)
for ndx in range(trk_p.ntargets):
    cci = pure_id[ndx]
    if cci<0 or np.isnan(cci):
        continue
    cur_gt = id_gt[int(cci)][ss[ndx]:ee[ndx]+1]
    if np.isnan(cur_gt[0]):
        continue
    # plt.plot([ss[ndx], ss[ndx]], [y_off[int(cur_gt[0])] - 0.5 + 0.02, y_off[int(cur_gt[0])] - 0.5 + y_sz[int(cur_gt[0])]/2 ], 'k', linewidth=1,zorder=10)

plt.xlim([fr_s-0.5,fr_e-0.5])

plt.ylim([-0.5,len(gt_id)-0.5])
plt.yticks(range(len(gt_id)))
# plt.gca().invert_yaxis()
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

plt.xlabel('Frame number')
plt.ylabel('Labeled ID')
f.tight_layout()

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_gt_id_map_crop_{intv}.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_gt_id_map_crop_{intv}.svg',dpi='figure')


# make a movie of the above
out_file = f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_id_example_mov_{idx}_{intv}.avi'
fps = 10
fourcc = cv2.VideoWriter_fourcc(*'X264')
x = [bcenter[0]-bsz_x,bcenter[0]+bsz_x]
y = [bcenter[1]-bsz_y,bcenter[1]+bsz_y]

f = plt.figure(figsize=[4,4*(y[1]-y[0])/(x[1]-x[0])])
f.set_dpi(100)
ax = f.add_axes([0, 0, 1, 1])
trk_fr = pp[conf.ht_pts]

offset = np.array([x[0], y[0]])
cc = colors
skel = [[0,1]]

for fr in range(fr_s, fr_e):
    ax.clear()
    im = cap.get_frame(fr)[0]
    if im.ndim == 2:
        im = cv2.cvtColor(im, cv2.COLOR_GRAY2RGB)
    ax.imshow(im[y[0]:y[1], x[0]:x[1]])
    ax.axis('off')

    for ix in range(trk_fr.shape[3]):
        dskl(trk_fr[..., fr - fr_s, ix] - offset[None], skel, cc=cc[ix])
        # gpts = gg[fr - fr_s, gt_id[ix]] - offset[None]
        if ix>=len(gt_matches):
            continue
        gid = np.where(np.array(gt_matches)==ix)[0][0]
        gpts = gg[fr - fr_s, gid] - offset[None]
        gpts = shift_line_segment(gpts[0], gpts[1], 2)
        dskl(gpts, skel, cc=cc[ix], ls=(0, (1, 1)))

    ax.set_xlim([0, x[1] - x[0]])
    ax.set_ylim([ y[1] - y[0],0])
    f.canvas.draw()
    img = np.frombuffer(f.canvas.tostring_rgb(), dtype=np.uint8)
    img = img.reshape(f.canvas.get_width_height()[::-1] + (3,))
    if fr == fr_s:
        fr_sz = img.shape[:2]
        out = cv2.VideoWriter(out_file, fourcc, fps, (fr_sz[1], fr_sz[0]))

    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    out.write(img)

out.release()

##

from matplotlib import patches

pad = 100
pp = trk_i.getframe(range(fr_s-pad,fr_e+1+pad))

gg = []
for ndx in range(fr_s-pad,fr_e+1+pad):
    gg.append(get_trx_frame(gt_trx_dict,ndx))
gg = np.array(gg)

sims = ims.transpose([1,0,2])
sims = sims.reshape([sims.shape[0],-1])
gpts = gg - bcenter[None] + np.array([bsz_x, bsz_y])[None]
gpts[gpts<0] = np.nan
gpts[gpts>2*np.array([bsz_x, bsz_y])]=[np.nan]

f = plt.figure(figsize=[8,1.5])
ax = f.add_axes([0,0,1,1])
ax.imshow(sims,cmap='gray')
offset = ims.shape[1]/200*np.arange(-pad,fr_e-fr_s+1+pad)
gpts[...,0] = gpts[...,0] + offset[:,None,None]


for curp in range(ngt):
    # sx = gt_id[curp]
    sx = curp
    for fr in range(fr_s-pad,fr_e+1+pad):
        if sx in id_gt[:,fr]:
            lw=0.5
        else:
            lw=2
        plt.plot(np.mean(gpts[fr-fr_s+pad:fr-fr_s+2+pad,sx,:,0],axis=1),np.mean(gpts[fr-fr_s+pad:fr-fr_s+2+pad,sx,:,1],axis=1),color=colors[gt_matches[curp]],linewidth=lw)

for fr in range(fr_s,fr_e+1,200):
    # if fr%100==0:
    #     lw = 2
    # else:
    #     lw = 0.5
    for curp in range(ngt):
        sx = curp
        pc = gpts[fr-fr_s+pad,sx]
        center = np.nanmean(pc,axis=0)
        major_axis_len = np.linalg.norm(pc[0]-pc[1])
        minor_axis_len = 20
        angle = np.degrees(np.arctan2(pc[1,1] - pc[0,1], pc[1,0] - pc[0,0]))

        ellipse = patches.Ellipse(center, major_axis_len, minor_axis_len, angle, edgecolor=colors[gt_matches[curp]], facecolor='none',linewidth=0.5,zorder=0)
        ax.add_patch(ellipse)
        # plt.plot(gpts[fr-fr_s,sx,:,0],gpts[fr-fr_s,sx,:,1],color=colors[gt_matches[curp]],linewidth=2,zorder=0)


plt.xlim([0,sims.shape[1]])
plt.ylim([sims.shape[0],0])
plt.axis('off')

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_gt_traj_{fr_s}.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_gt_traj_{fr_s}.svg',dpi='figure')

#
f1 = plt.figure(figsize=[8,1.5])
ax = f1.add_axes([0,0,1,1])
ax.imshow(sims,cmap='gray')

ppts = pp - bcenter[:,None,None] + np.array([bsz_x, bsz_y])[:,None,None]
ppts[ppts<0] = [np.nan]
ppts[ppts>2*np.array([bsz_x, bsz_y])[:,None,None]]=[np.nan]
ppts[:,0] = ppts[:,0] + offset[:,None]
ppts = ppts[info[idx]['ht_pts']]
for curp in range(pp.shape[3]):
    if np.all(np.isnan(np.mean(ppts[:,0,:,curp],axis=0))):
        continue
    pss = np.mean(ppts[:,:,:,curp],axis=0)
    # alpha = 1-((pss[0]>2*bsz_x)|(pss[0]<0)|(pss[1]>2*bsz_y)|(pss[1]<0))
    plt.plot(pss[0],pss[1],color=colors[curp],linewidth=1)

for fr in range(fr_s,fr_e+1,200):
    # if fr%100==0:
    #     lw = 2
    # else:
    #     lw = 0.5
    for curp in range(pp.shape[3]):

        pc = ppts[...,fr-fr_s+pad,curp]
        center = np.nanmean(pc,axis=0)
        major_axis_len = np.linalg.norm(pc[0]-pc[1])
        minor_axis_len = 20
        angle = np.degrees(np.arctan2(pc[1,1] - pc[0,1], pc[1,0] - pc[0,0]))

        ellipse = patches.Ellipse(center, major_axis_len, minor_axis_len, angle, edgecolor=colors[curp], facecolor='none',linewidth=0.5,zorder=0)
        ax.add_patch(ellipse)

        # plt.plot(ppts[:,0,fr-fr_s,curp],ppts[:,1,fr-fr_s,curp],color=colors[curp],linewidth=2,zorder=0)

for ndx,scur in enumerate(ss):
    if scur>=(fr_s-pad) and scur<=(fr_e+pad):
        ppc = trk_p.gettargetframe(ndx,scur)[:,:,0,0]
        ppc = ppc[conf.ht_pts].mean(axis=0)
        cci = pure_id[ndx]
        if cci < 0 or np.isnan(cci):
            continue
        cci = int(cci)
        curc = colors[cci]
        ppc = ppc - bcenter + np.array([bsz_x, bsz_y])
        ppc[ppc<0] = np.nan
        ppc[ppc>2*np.array([bsz_x, bsz_y])]=[np.nan]
        ppc[0] += offset[scur-fr_s+pad]
        plt.scatter(ppc[0],ppc[1],color=curc,s=5)


plt.xlim([0,sims.shape[1]])
plt.ylim([sims.shape[0],0])
plt.axis('off')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_pred_traj_{fr_s}.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_{motion_type}_pred_traj_{fr_s}.svg',dpi='figure')

## Show examples of ambiguity and jumps


kk = trk_i.getframe(range(nfr))
dd = np.linalg.norm(kk[:,:,1:,None,:]-kk[:,:,:-1,:,None],axis=0).mean(axis=0)
dd = np.partition(dd,1,axis=-1)
cd = np.nanmin(dd[...,1]/dd[...,0],axis=-1)
ocd = np.argsort(cd)

## show tracklets for an interval

from matplotlib.colors import ListedColormap, Normalize
from matplotlib.cm import ScalarMappable

cap = movies.Movie(info[idx]['mov_file'])

f = plt.figure(figsize=[3,3])
f.set_dpi(100)
ax = f.add_axes([0, 0, 1, 1])

if idx==1:
    # fr_s = 4000#31000
    # fr_e = fr_s+1000
    fr_s = 43000
    fr_e = 44000
elif idx==4:
    fr_s = 9400
    fr_e = 9600

im = cap.get_frame(fr_s)[0]
if im.ndim == 2:
    im = cv2.cvtColor(im, cv2.COLOR_GRAY2RGB)
ax.imshow(im)
ax.axis('off')
plt.axis('equal')

trk_fr = trk_i.getframe(range(fr_s,fr_e))
trk_fr = trk_p.getframe(range(fr_s,fr_e))
trk_fr = trk_fr[conf.ht_pts].mean(axis=0)
colors = pt.get_cmap(fr_e-fr_s,'hsv')

cmap = ListedColormap(colors)
# Create a Normalize object
norm = Normalize(vmin=fr_s, vmax=fr_e)
# Create a ScalarMappable
scalar_mappable = ScalarMappable(norm=norm, cmap=cmap)

for tt in range(trk_fr.shape[2]):
    # for ix in range(trk_fr.shape[1]-1):
    #     ax.plot(trk_fr[0,ix:ix+2,tt],trk_fr[1,ix:ix+2,tt],color=colors[ix])#,alpha=0.8,linewidth=0.5)
    ax.scatter(trk_fr[0,:,tt],trk_fr[1,:,tt],color=colors,marker='.',alpha=0.3,edgecolors='none')

axc = f.add_axes([0.02,0.02,0.05,0.1])
cbar = plt.colorbar(scalar_mappable, cax=axc,location='right')
cbar.ax.tick_params(colors=[1,0.25,0.25],labelsize=8)

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_trajectories_{idx}_{fr_s}.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_trjectories_{idx}_{fr_s}.svg')

trk_fr = trk_p.getframe(range(fr_s,fr_e))
trk_fr = trk_fr[conf.ht_pts].mean(axis=0)
ss,ee = trk_p.get_startendframes()
for ndx,curs in enumerate(ss):
    if curs>=fr_s and curs<=fr_e:
        ax.scatter(trk_fr[0,curs-fr_s,ndx],trk_fr[1,curs-fr_s,ndx],marker='x', color='r',s=100)

plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_trajectories_{idx}_{fr_s}_breaks.png')
plt.savefig(f'/groups/branson/home/kabram/temp/{info[idx]["name"]}_trjectories_{idx}_{fr_s}_breaks.svg')

## maxcost threshold plot.. use idx=2

costs = []
miss = []
frs  = []
ids = []
ids1 = []
for ndx in range(nfr-1):
    ss1 = np.where(np.all(~np.isnan(gt_trk[ndx,...,0]),axis=-1))[0]
    ss2 = np.where(np.all(~np.isnan(gt_trk[ndx+1,...,0]),axis=-1))[0]
    dd = np.nanmean(np.abs(gt_trk[ndx,ss1,None]-gt_trk[None,ndx+1,ss2]),axis=(-1,-2))
    # g1 = get_trx_frame(gt_trx_dict,ndx)
    # g2 = get_trx_frame(gt_trx_dict,ndx+1)
    # dd = np.mean(np.abs(g1[None]-g2[:,None]),axis=(-1,-2))

    idp,idg = opt.linear_sum_assignment(dd)
    costs.extend(dd[idp,idg].tolist())
    miss.extend( (ss1[idp]!=ss2[idg]).tolist())
    ids.extend(ss1[idp])
    ids1.extend(ss2[idg])
    # miss.extend( (idp!=idg).tolist())
    # ids.extend(idp)
    # ids1.extend(idg)
    frs.extend([ndx,]*len(idp))

costs = np.array(costs)
miss = np.array(miss)
frs = np.array(frs)
ids = np.array(ids)
ids1 = np.array(ids1)

cx = np.argsort(costs)
cc1 = costs[cx]
mm1 = miss[cx]
rr1 = np.arange(len(costs))
plt.figure()
plt.scatter(rr1[~mm1],cc1[~mm1],c='b',marker='.')
plt.scatter(rr1[mm1],cc1[mm1],c='r',marker='x')
plt.hlines(maxcost/2,0,rr1.max(),colors='k')
plt.ylim([0,10])

## second closest threshold plot.. use idx=2

costs_2 = []
miss_2 = []
frs_2  = []
ids_2 = []
ids1_2 = []
for ndx in range(nfr-1):
    ss1 = np.where(np.all(~np.isnan(gt_trk[ndx,...,0]),axis=-1))[0]
    ss2 = np.where(np.all(~np.isnan(gt_trk[ndx+1,...,0]),axis=-1))[0]
    dd = np.nanmean(np.abs(gt_trk[ndx,ss1,None]-gt_trk[None,ndx+1,ss2]),axis=(-1,-2))
    # g1 = get_trx_frame(gt_trx_dict,ndx)
    # g2 = get_trx_frame(gt_trx_dict,ndx+1)
    # dd = np.mean(np.abs(g1[None]-g2[:,None]),axis=(-1,-2))

    ids_2.extend(ss1)

    idp,idg = opt.linear_sum_assignment(dd)
    miss_2.extend( (ss1[idp]!=ss2[idg]).tolist())
    for ndx1 in idp:
        if len(dd[ndx1])>1:
            qq = np.partition(dd[ndx1],1)
            vv = qq[1]/qq[0]
            costs_2.append(qq[1] / qq[0])
        else:
            costs_2.append(10)

    # miss.extend( (idp!=idg).tolist())
    # ids.extend(idp)
    # ids1.extend(idg)
    frs_2.extend([ndx,]*len(idp))

costs_2 = np.array(costs_2)
miss_2 = np.array(miss_2)
frs_2 = np.array(frs_2)
ids_2 = np.array(ids_2)
ids1_2 = np.array(ids1_2)

cx = np.argsort(costs_2)
cc1 = costs_2[cx]
mm1 = miss_2[cx]
rr1 = np.arange(len(costs_2))
plt.figure()
plt.scatter(rr1[~mm1],cc1[~mm1],c='b',marker='.')
plt.scatter(rr1[mm1],cc1[mm1],c='r',marker='x')
plt.hlines(2,0,rr1.max(),colors='k')
plt.ylim([0,10])

## show the example for second closest threshold plot.. use idx=7

mxx = np.where( (costs_2<2)&(costs<maxcost))

if idx ==7:
    fr = 38316
    sz = 80
elif idx == 9:
    fr = 105642
    sz = 160
p1 = trk_p.getframe(fr)[:,:,0]
p2 = trk_p.getframe(fr+1)[:,:,0]
v1 = np.where(np.all(~np.isnan(p1[:,0]),axis=0))[0]
p1 = p1[:,:,v1]
v2 = np.where(np.all(~np.isnan(p2[:,0]),axis=0))[0]
p2 = p2[:,:,v2]

dd = np.nanmean(np.abs(p1[:,:,None] - p2[...,None]), axis=(0, 1))
if idx==7:
    dkk = np.partition(dd, 1,axis=1)
    sjj = np.where(dkk[:,1]/dkk[:,0]<2)[0][0]
    ss = np.where(dd[sjj]<=dkk[sjj,1])[0]
    ss1 = np.argmin(dd[:,ss],axis=0)
    p1_s = p1[:,:,ss1]
    p2_s = p2[:,:,ss]
else:
    dkk = np.partition(dd, 1,axis=0)
    sjj = np.where(dkk[1]/dkk[0]<2)[0][0]
    ss = np.where(dd[:,sjj]<=dkk[1,sjj])[0]
    ss1 = np.argmin(dd[ss,:],axis=1)
    p1_s = p1[:,:,ss1]
    p2_s = p2[:,:,ss]

cap = movies.Movie(info[idx]['mov_file'])
frm = cap.get_frame(fr)[0]
bcenter = np.nanmean(np.concatenate([p1_s,p2_s],axis=0),axis=(0,2)).astype('int')
im = frm[bcenter[1]-sz:bcenter[1]+sz,bcenter[0]-sz:bcenter[0]+sz]
plt.figure()
plt.imshow(im,cmap='gray')
plt.axis('off')
mdskl(p1_s.transpose(2,0,1)-bcenter[None,None]+sz,conf.op_affinity_graph,cc='r')
mdskl(p2_s.transpose(2,0,1)-bcenter[None,None]+sz,conf.op_affinity_graph,cc='b')


## show the miss link with lowest cost
oxx = np.argsort(costs[miss])
soxx = 3
cap = movies.Movie(mov_file)
sfr = frs[miss][oxx[soxx]]
sid = ids[miss][oxx[soxx]]
sid1 = ids1[miss][oxx[soxx]]

p1 = gt_trk[sfr,sid]
p2 = gt_trk[sfr+1,sid1]
bcenter = np.nanmean(np.concatenate([p1,p2],axis=0),axis=0).astype('int')
bsz = 70

frm = cap.get_frame(sfr)[0]
im = frm[bcenter[1]-bsz:bcenter[1]+bsz,bcenter[0]-bsz:bcenter[0]+bsz]
plt.figure()
plt.imshow(im,cmap='gray')
plt.axis('off')
skel = np.array(conf.op_affinity_graph)
dskl(p1-bcenter[None]+bsz,skel,plt.gca(),cc='r')
dskl(p2-bcenter[None]+bsz,skel,plt.gca(),cc='c')



##

lid = 3
sel_pure = np.where(pure_links[sel_tgt,1]==lid)[0]

lco = []
for xx in link_costs:
    if len(xx[1]) > 0:
        lco.append(np.min(xx[1][:, -1]))
    else:
        lco.append(np.nan)

lco = np.array(lco)

# sel_start = sel_tgt[295]
# sel_end = int(link_type[sel_start,1])
if idx==3:
    sel_start = 41
    sel_end = 50
    others = np.where( (ss>ee[sel_start]) & (ss<ss[sel_end]) )[0]

fr_s = ee[sel_start]-2
fr_e = ss[sel_end]+2
p1 = trk_p.gettargetframe(sel_start,range(fr_s,ee[sel_start]+1))[...,0]
p2 = trk_p.gettargetframe(sel_end,range(ss[sel_end],fr_e+1))[...,0]
po = trk_p.gettargetframe(others,range(fr_s,fr_e+1))

p12 = np.concatenate([p1,p2],axis=2)
bcenter = np.nanmean(p12[info[idx]['ht_pts']],axis=(0,2)).astype('int')
bsz = 90
ims = []
cap = movies.Movie(info[idx]['mov_file'])
for fr in range(fr_s,fr_e+1):
    im = cap.get_frame(fr)[0]
    im = im[bcenter[1]-bsz:bcenter[1]+bsz,bcenter[0]-bsz:bcenter[0]+bsz]
    ims.append(im)
ims = np.array(ims)

##
f,ax = plt.subplots(1,ims.shape[0],figsize=(10,5),sharex='all',sharey='all')
skel = np.array(conf.op_affinity_graph)
for i in range(ims.shape[0]):
    ax[i].imshow(ims[i],cmap='gray')
    ax[i].axis('off')
for i in range(3):
    # ax[i].imshow(ims[i],cmap='gray')
    # ax[i].axis('off')
    dskl(p1[...,i]-bcenter[None]+bsz,skel,ax[i],cc='r')
    # ax[-i-1].imshow(ims[-i-1],cmap='gray')
    # ax[-i-1].axis('off')
    dskl(p2[...,i]-bcenter[None]+bsz,skel,ax[-i-1],cc='b')

for i in range(ims.shape[0]-5):
    fwd_v = p1[...,-2]-p1[...,-1]
    fwd_p = p1[...,-1]+fwd_v*(i+1)
    dskl(fwd_p-bcenter[None]+bsz,skel,ax[i+3],cc='r',alpha=0.3)
    bck_v = p2[...,1]-p2[...,0]
    bck_p = p2[...,0]+bck_v*(i+1)
    dskl(bck_p-bcenter[None]+bsz,skel,ax[-i-4],cc='b',alpha=0.3)

for i in range(ims.shape[0]):
    curo = po[...,i,:]-bcenter[None,:,None]+bsz
    curo = curo.transpose([2,0,1])
    mdskl(curo,skel,ax=ax[i],cc='g',alpha=0.3)

## old. not used


## Find the embeddings for each selected GT tracklet
import tqdm

cap = movies.Movie(mov_file)
int_preds = np.ones([nfr,trk_i.ntargets,32])*np.nan
for fr in tqdm.tqdm(range(0,nfr)):
    idp = trk_i.getframe(ndx)[:,:,0].transpose([2,0,1])
    vv = np.where(np.all(~np.isnan(idp[:,:,0]),axis=1))[0]
    to_do_list = [[fr,ix] for ix in vv]
    ims = apt.create_batch_ims(to_do_list,conf,cap,False,id_trx,None,use_bsize=False)
    ims = lnk.process_id_ims(ims,conf,False,1.)
    ims = torch.from_numpy(ims).float().cuda()
    pp = lnk.do_pred(ims,net)
    int_preds[fr,vv] = pp

id_embed = np.nanmean(int_preds,axis=0)

##

# gt_mean = np.nanmean(int_preds,axis=0)
d_gt = []
d_other = []
for ix,gt_idd in enumerate(range(id_trk.ntargets)):
    dist_gt = np.linalg.norm(int_preds[:,gt_idd]-id_embed[gt_idd,None],axis=-1)
    gt_other = np.array([id_embed[xx] for xx in range(id_embed.shape[0]) if xx!=gt_idd])
    dist_other = np.nanmin(np.linalg.norm(int_preds[None,:,gt_idd]-gt_other[:,None],axis=-1),axis=0)
    d_gt.append(dist_gt)
    d_other.append(dist_other)
d_gt = np.array(d_gt)
d_other = np.array(d_other)


## show id embedding distance for each frame for each ID tracklet

sel_ids_show = list(range(10))
f = plt.figure(figsize=(10,5))
# f,ax = plt.subplots(len(sel_ids_show),1,figsize=(10,5),sharex='all')
t1=0;t2=nfr
# cc = pt.get_cmap(3,'winter')
cc = pt.get_cmap(5,'hsv')
cc = ['b','violet','c','r','g']
lw = [0.5,1,1,1,1]
lw = [0.5,]*5
done = np.zeros([nfr,2])
ax = []
m = 0.01
base = 0.1
top = 0.05
xbase = 0.05
ysz = (1-base-top-(len(sel_ids_show)-1)*m)/len(sel_ids_show)
nt = len(sel_ids_show)
for ndx,sel_id in enumerate(sel_ids_show):
    starty = base+(nt-ndx-1)*(ysz+m)
    ax.append(f.add_axes([xbase,starty,1-xbase-0.01,ysz]))
    ax[ndx].plot(np.arange(t1,t2),d_gt[ndx],linewidth=0.5,
    alpha=0.5)
    ax[ndx].plot(np.arange(t1,t2),d_other[ndx],linewidth=0.5,alpha=0.5)
    # ax[ndx].set_title(f'Tracklet {id_ids[ndx]}')
    ax[ndx].set_ylim([0,2.4])
    sj = np.where(pure_id==sel_id)[0]
    for sjj in sj:
        if (pure_links[sjj,0] == 0) or np.isnan(pure_links[sjj,0]):
            print(f'No forward link to {sjj},({ss[sjj]}) in {sel_id}')
            continue
        elif (done[ss[sjj],0]==0) or (done[ss[sjj],1]<pure_links[sjj,0]):
            ax[ndx].axvline(ss[sjj], c=cc[int(pure_links[sjj, 0]) - 1], linewidth=lw[int(pure_links[sjj, 0])-1])
            done[ss[sjj],0] = 1
            done[ss[sjj],1] = pure_links[sjj,0]

        if (pure_links[sjj,1] == 0) or np.isnan(pure_links[sjj,1]):
            print(f'No backward link to {sjj},({ee[sjj]}) in {sel_id}')
            continue
        elif (done[ee[sjj],0]==0) or (done[ee[sjj],1]<pure_links[sjj,1]):
            ax[ndx].axvline(ee[sjj], c=cc[int(pure_links[sjj, 1]) - 1], linewidth=lw[int(pure_links[sjj, 1])-1])
            done[ee[sjj],0] = 1
            done[ee[sjj],1] = pure_links[sjj,1]

    ax[ndx].spines['top'].set_visible(False)
    ax[ndx].spines['right'].set_visible(False)


    if ndx==len(sel_ids_show)-1:
        ax[ndx].set_xlabel('Frame number')
    elif ndx==len(sel_ids_show)//2:
        ax[ndx].set_ylabel('Dist. to mean embedding')
        # ax[ndx].set_xticks([])
    # else:
    #     ax[ndx].set_xticks([])
    if ndx>0:
        ax[ndx].sharex(ax[0])
    # else:
    #     ax[ndx].set_xticklabels([])
    #     ax[ndx].set_xticks([])
    # if ndx==0:
    #     ax[ndx].legend(['Self','Other'])
f.tight_layout()


## cluster the motion groups above

tr_len = [cur_ee - cur_ss + 1]
tlen = []
for pp in pred_map:
    tlen.append(tr_len[pp[0]][pp[1]])
tlen = np.array(tlen)

motion_grs_all = []
sel_ids = []
for m in motion_grs:
    motion_grs_all.append([0, m])
    cur_sel_ids = []
    for mm in m:
        gndx = np.where(np.all(pred_map == np.array([0, mm]), axis=1))[0]
        if len(gndx) > 0:
            cur_sel_ids.append(gndx[0])
    sel_ids.append(cur_sel_ids)

nsel = len(sel_ids)
xmat = np.zeros([nsel, nsel])
for x1, s1 in enumerate(sel_ids):
    for x2, s2 in enumerate(sel_ids):
      cmat = dist_mat[s1][:, s2].copy()
      if x1 == x2:
        if len(s1) == 1:
          cmat[range(len(s1)), range(len(s1))] = np.nan
        else:
          cmat[range(len(s1)), range(len(s1))] = 2.
      mx1 = np.average(np.min(cmat,axis=0),weights=tlen[s2])
      mx2 = np.average(np.min(cmat,axis=1),weights=tlen[s1])
      xmat[x1,x2] = (mx1+mx2)/2

xthresh = np.nanpercentile(np.diag(xmat), 90)
xthresh = max(close_thresh,xthresh)

# diagnal as 0.
xmat[range(nsel), range(nsel)] = 0.

overlaps = np.zeros([nsel,nsel]) #overlap between different groups
mgr_lens = np.zeros(nsel)  # length of each group
mov_ndx = np.array([p[0] for p in motion_grs_all])

cur_mgrs = np.where(mov_ndx==0)[0]
lenso = np.zeros([len(cur_mgrs), maxn])
for nxx, gndx in enumerate(cur_mgrs):
  gi = motion_grs_all[gndx][1]
  for gii in gi:
    lenso[nxx, cur_ss[gii]:cur_ee[gii] + 1] = 1

for x1 in range(len(lenso)):
    mgr_lens[cur_mgrs[x1]] = np.sum(lenso[x1]>0)
for x1 in range(len(lenso)):
  for x2 in range(len(lenso)):
    if x1 >= x2: continue
    ll = np.sum((lenso[x1] * lenso[x2]) > 0)
    overlaps[cur_mgrs[x1],cur_mgrs[x2]] = ll
    overlaps[cur_mgrs[x2],cur_mgrs[x1]] = ll

# groups using linkage
F1 = lnk.weighted_linkage(xmat,overlaps,mgr_lens,xthresh)
F = np.zeros(nsel).astype('int')
for ndx, c in enumerate(F1):
    for cc in c:
      F[cc] = ndx+1

grs = []
ggv = []
gv_len = []
new_pred_map = []
gr_data = []
for gi in range(max(F)):
    gv = np.where(F == (gi + 1))[0]

    ggv.append(gv)
    curg = []
    clen = 0
    for gvv in gv:
      curmov = motion_grs_all[gvv][0]
      for g in motion_grs_all[gvv][1]:
        curg.append(len(new_pred_map))
        new_pred_map.append([curmov,g])
        clen += cur_ee[g] - cur_ss[g]+1
    grs.append(curg)
    gv_len.append(clen)
    gr_data.append([motion_grs_all[gvv] for gvv in gv])

new_pred_map = np.array(new_pred_map)
minv, maxv = trk_p.get_min_max_val()
minv = np.min(minv, axis=0)
maxv = np.max(maxv, axis=0)
bignumber = np.sum(maxv - minv) * 2000
maxcosts_all = [np.array([maxcost,]+maxcost_missed.tolist())]
grs, new_pred_map = lnk.add_missing_links([trk_p], grs, conf, new_pred_map, 0, None, maxcosts_all[0], maxn, bignumber, [link_costs])



##
gt_id = np.ones(id_pure_id.shape[1])*np.nan
group_links = [[] for _ in range(id_pure_id.shape[1])]
for ixx,curg in enumerate(gr_data):
    if gv_len[ixx]<100:
        continue
    gxx = [yy for xx in curg for yy in xx[1]]
    pxx = [zz for xx in curg for yy in xx[1] for zz in pure_id[yy] if not np.isnan(zz)]
    cx = np.bincount(pxx)
    cur_gt = np.argmax(cx)
    gt_id[cur_gt] = ixx
    for iyy,curgg in enumerate(curg):
        px = [yy for xx in curgg[1] for yy in pure_id[xx] if not np.isnan(yy)]
        cx = np.bincount(px)
        cur_gt1 = np.argmax(cx)
        if cur_gt1!=cur_gt:
            group_links[cur_gt].append([False,curgg])
        else:
            group_links[cur_gt].append([True,curgg])

## Assign pure tracklet, our assigned identity

import scipy.optimize as opt

npure = trk_p.ntargets
gt_i = np.ones(npure)*np.nan
tt = trk_p
ss,ee = tt.get_startendframes()

nfr = max(ee)+1
conf.has_trx_file= True
gt_trx_dict = apt.get_trx_info(info[idx]['fix_error_trx'],conf,nfr,use_ht_pts=True)
conf.has_trx_file= False
gt_trx = gt_trx_dict['trx']
tr = 0.7

gt_trk = np.ones([nfr,gt_trx_dict['n_trx']+1,conf.n_classes,2])*np.nan
gt_pure_id = np.ones([nfr,gt_trx_dict['n_trx']+1])*np.nan
ngt = gt_trx_dict['n_trx']
pure_id = [np.ones(e1-s1+1)*np.nan for s1,e1 in zip(ss,ee)]
count = np.zeros(nfr)
far = []
for ndx in range(nfr):
    p1 = tt.getframe(ndx)[:,:,0].transpose([2,0,1])
    p = p1[:,info[idx]['ht_pts']]
    vv = np.where(~np.all(np.isnan(p[:,:,0]),axis=1))[0]
    count[ndx] = len(vv)
    g = get_trx_frame(gt_trx_dict,ndx)
    # Find the matches using hungarian algorithm

    dd = np.sum(np.linalg.norm(p[vv,None]-g[None],axis=(-1)),axis=-1)
    # dd[0] has match for p[0], dd[:,0] has match for g[0]
    sz = np.linalg.norm(g[:,0]-g[:,1],axis=-1).mean()
    dd_m = dd/sz
    idp,idg = opt.linear_sum_assignment(dd_m)

    for npp,ng in zip(idp,idg):

        if dd_m[npp,ng]>np.sqrt(2):
            print(f'Frame {ndx}, gt {ng} has large distance')
            gt_trk[ndx,ngt] = p1[vv[npp]]
            gt_pure_id[ndx,ngt] = vv[npp]
            pure_id[vv[npp]][ndx-ss[vv[npp]]] = ngt
            far.append([ndx,npp,ng])
            continue

        gt_trk[ndx,ng] = p1[vv[npp]]
        gt_pure_id[ndx,ng] = vv[npp]
        pure_id[vv[npp]][ndx-ss[vv[npp]]] = ng

    if dd_m.shape[0]>ngt:
        extra = list(set(range(dd_m.shape[0]))-set(idp))[0]
        gt_trk[ndx,ngt] = p1[vv[extra]]
        gt_pure_id[ndx,ngt] = vv[extra]
        pure_id[vv[extra]][ndx-ss[vv[extra]]] = ngt

pure_assigned_id = []
id_parts = [[] for _ in range(trk_i.ntargets)]
missed = []
id_pure_id = np.ones([nfr,trk_i.ntargets])*np.nan
id2gt = np.ones([nfr,trk_i.ntargets])*np.nan
for ndx in range(trk_p.ntargets):

    ff = trk_i.getframe(range(ss[ndx],ee[ndx]+1))
    dd = np.sum(np.abs(ff-trk_p.pTrk.data[ndx][...,None]),axis=(0,1,2))
    if len(np.where(dd==0)[0])==0:
        missed.append(ndx)
    else:
        cur_id = np.where(dd==0)[0][0]
        pure_assigned_id.append(cur_id)
        id_parts[cur_id].append(ndx)
        id_pure_id[ss[ndx]:ee[ndx]+1,cur_id] = ndx
        id2gt[ss[ndx]:ee[ndx]+1,cur_id] = pure_id[ndx]

gt2id = np.ones([ngt])*np.nan
counts = np.zeros([ngt])
for ndx in range(trk_i.ntargets):
    eqq = id2gt[:,ndx]
    eqq = eqq[~np.isnan(eqq)].astype('int')
    kk = np.bincount(eqq)
    pgt = eqq[np.argmax(kk)]
    if np.max(kk)<counts[pgt]:
        continue
    gt2id[pgt] = ndx
    counts[pgt] = np.max(kk)

## Find where the breaks are

tr1 = 8.240892/2
tr2 = 2

# dg1 = np.nanmean(np.abs(gt_trk[1:,None]-gt_trk[:-1,:,None]),axis=(-1,-2))
id_ptrk = trk_i.getframe(range(nfr))[...,:info[idx]['n_animals']].transpose([2,3,0,1])
dg1 = np.nanmean(np.abs(id_ptrk[1:,None]-id_ptrk[:-1,:,None]),axis=(-1,-2))
dg = np.partition(dg1,1,axis=-1)

v1 = dg[:,:,0]
v2 = dg[:,:,1]/dg[:,:,0]

brks1 = np.where((v1>tr1) | (v2<tr2))
brks = np.where( (id_pure_id[1:]!=id_pure_id[:-1])&~(np.isnan(id_pure_id[1:])&np.isnan(id_pure_id[:-1])) )
# brks1 = np.where( (gt_pure_id[1:]!=gt_pure_id[:-1])&~(np.isnan(gt_pure_id[1:])&np.isnan(gt_pure_id[:-1])) )
# breaks will have more than brks1 because of missed detections

##
# Find the embeddings for each GT tracklet
gt_embed = []
for i1 in range(gt_pure_id.shape[1]):
    gg = gt_pure_id[:,i1]
    gg = gg[~np.isnan(gg)]
    cur_ids = np.unique(gg)
    cur_emb = []
    sel_gt = []
    for xx in cur_ids:
        cur_x = np.where(sel_tgt==xx)[0]
        if len(cur_x)==0:
            continue
        cur_emb.append(preds[cur_x])
        sel_gt.append([xx,cur_x[0]])
    gt_embed.append([np.array(cur_emb),np.array(sel_gt)])




## plot the frame matching cost and mark where the breaks are

# t1 = 43400; t2 = 43700
# sel_ids = [3,1,7]
# id_ids = [1,3,10] # id assigned by our id tracker
t1 = 0; t2 = nfr-1
sel_ids_show = list(range(id_trk.ntargets))
id_ids = list(range(id_trk.ntargets))

f,ax = plt.subplots(len(sel_ids_show),1,figsize=(5,2.5),sharex='all')
ax = ax.flatten()
for ndx,sel_id in enumerate(sel_ids_show):
    ax[ndx].plot(np.arange(t1,t2),v1[t1:t2][:,sel_ids_show[ndx]],linewidth=0.5,alpha=0.5); plt.ylim([0,5.5])
    b1 = brks[0][(brks[0]>=t1) & (brks[0]<t2)& (brks[1]==sel_ids_show[ndx])]
    # ax[ndx].scatter(b1,5.25*np.ones_like(b1),c='r',s=10,marker='x')
    for bb in b1:
        if np.isnan(v1[bb-1,sel_ids_show[ndx]])&np.isnan(v1[bb+1,sel_ids_show[ndx]]):
            continue
        elif v1[bb,sel_ids_show[ndx]]>tr1:
            ax[ndx].axvline(bb,c='r',linewidth=0.5)
        else:
            ax[ndx].axvline(bb,c='g',linewidth=1)
    ax[ndx].set_ylim([0,5.5])
    ax[ndx].spines['top'].set_visible(False)
    ax[ndx].spines['right'].set_visible(False)
    if ndx==len(sel_ids_show)-1:
        ax[ndx].set_xlabel('Frame number')
    elif ndx==len(sel_ids_show)//2:
        ax[ndx].set_ylabel('Dist. between frms')
        # ax[ndx].set_xticklabels([])
        # ax[ndx].set_xticks([])
    else:
        pass
        # ax[ndx].set_xticklabels([])
        # ax[ndx].set_xticks([])
    # ax[ndx].set_title(f'Tracklet {id_ids[ndx]}')
    ax[ndx].tick_params(axis='both', which='major',labelsize=7)

f.tight_layout(pad=0.01)


## Find the breaks that got linked

bqq = list(zip(*brks))
found = np.zeros(len(bqq))
extra = []
for ndx,sel_id in enumerate(sel_ids_show):
    pp = gt_pure_id[t1:t2,sel_id]
    sj = np.unique(pp[~np.isnan(pp)].astype('int'))
    for sjj in sj:
        if link_type[sjj,0] == 0: continue
        mid = [sjj in mm for mm in motion_grs].index(True)
        end_pt = int(link_type[sjj,1])
        cur_pts = list(set(motion_grs[mid])-set([sjj])-set([end_pt]))
        # if bqq.count((ee[sjj],sel_id))>0:
        found[bqq.index((ee[sjj],sel_id))] = 1

        # if bqq.count((ss[end_pt],sel_id))>0:
        found[bqq.index((ss[end_pt]-1,sel_id))] = 1
        for ccx in cur_pts:
            # if bqq.count((ss[ccx],sel_id))>0:
            if ss[ccx]>0:
                found[bqq.index((ss[ccx]-1,sel_id))] = 1
            # if bqq.count((ee[ccx],sel_id))>0:
            if ee[ccx]<t2:
                found[bqq.index((ee[ccx],sel_id))] = 1

    gt_idd = int(gt_id[sel_id])
    for ix in range(len(group_links[gt_idd])):
        correct,curg = group_links[gt_idd][ix]
        cur_s = ss[curg[1][0]]
        cur_e = ee[curg[1][-1]]

        # if bqq.count((cur_s,gt_idd))>0:
        if cur_s>0:
            found[bqq.index((cur_s-1,gt_idd))] = 1
        # if bqq.count((cur_e,gt_idd))>0:
        if cur_e < t2:
            found[bqq.index((cur_e,gt_idd))] = 1


not_found = np.where(found==0)[0]
lls = []
for nf in not_found:
    if bqq[nf][1] not in sel_ids_show:
        continue
    id = gt_pure_id[bqq[nf][0],sel_ids_show[bqq[nf][1]]]
    if np.isnan(id):
        print('Nan')
        continue
    lls.append([bqq[nf],nf,id,ee[int(id)]-ss[int(id)]+1])


####################
####################
# OLD CODE
####################
####################

mov_file = '/groups/branson/home/robiea/Projects_data/Labeler_APT/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie.ufmf'
ctrax = '/groups/branson/home/robiea/Projects_data/Labeler_APT/cx_GMR_SS00030_CsChr_RigC_20150826T144616/registered_trx.mat'
#id_trk = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/cx_GMR_SS00030_CsChr_RigC_20150826T144616_bbox.trk'
id_trk = '/groups/branson/home/kabram/temp/ar_id.trk'

fix_error_trx = '/groups/branson/home/kabram/temp/fixed_id_trx_break.mat'
ht_pts = [0,6]

tracklet = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/cx_GMR_SS00030_CsChr_RigC_20150826T144616_bbox_tracklet.trk'

id_wts = '/groups/branson/home/kabram/temp/ma_expts/alice/trks/cx_GMR_SS00030_CsChr_RigC_20150826T144616_bbox_idwts.p'

out_files = ['/groups/branson/home/kabram/temp/a.trk']

out_mined_dir = '/groups/branson/home/kabram/temp/ar_id_mined_ims'
import os
if  not os.path.exists(out_mined_dir):
    os.mkdir(out_mined_dir)

t1 = 4000
t2 = 5000
sel_t = 4500-1


## generate hard mining examples

import TrkFile
import link_trajectories as lnk
from poseConfig import conf
import movies
import APT_interface as apt
from tqdm import tqdm
import torch
from torch import optim
import torch.nn.functional as F
import copy
import numpy as np
import cv2

trk_p = [TrkFile.Trk(tt) for tt in [tracklet]]

# do id tracking

for k in trk_p[0].trkData['trkInfo']['params']:
    conf.__dict__[k] = trk_p[0].trkData['trkInfo']['params'][k]

conf.has_trx_file = False
conf.use_bbox_trx = False
conf.use_ht_trx = True
conf.img_dim = 3
conf.trx_align_theta = True
conf.link_id = True
# conf.ht_pts = (0,1)
conf.ht_pts = (0,6)
conf.imsz = [conf.multi_animal_crop_sz,conf.multi_animal_crop_sz]

#trk_p = [lnk.link_pure(tt,conf) for tt in trk_p]

#trk_i = lnk.link_id(trk_p, [tracklet], [mov_file], conf, out_files, None)


##
if __name__ == '__main__':
    cap = movies.Movie(mov_file)
    trx_dict = apt.get_trx_info(tracklet, conf, cap.get_n_frames(), use_ht_pts=True)
    trx = trx_dict['trx']
    all_trx= [trx]
    cap.close()

    train_data = lnk.get_id_train_images(trk_p, all_trx, [mov_file], conf)

    all_data = train_data

    class ContrastiveLoss(torch.nn.Module):
        """
        Contrastive loss function.
        Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
        """

        def __init__(self, margin=2.0):
            super(ContrastiveLoss, self).__init__()
            self.margin = margin

        def forward(self, output1, output2, label):
            euclidean_distance = F.pairwise_distance(output1, output2, keepdim=True)
            loss_contrastive = torch.sum((1 - label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(
                torch.clamp(self.margin - euclidean_distance, min=0.0), 2))

            return loss_contrastive


    loss_history = []

    net = lnk.get_id_net()
    criterion = ContrastiveLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.0001)

    # Create a new conf object so that we can use the posetools preprocessing function. However, we need to change the augmentation parameters and cropping parameters that are appropriate for the cropped images

    bsz = 16
    confd = copy.deepcopy(conf)
    if confd.trx_align_theta:
        confd.rrange = 10.
    else:
        confd.rrange = 180.
    confd.trange = min(conf.imsz) / 15
    # no flipping business for id
    confd.horz_flip = False
    confd.vert_flip = False
    confd.scale_factor_range = 1.1
    confd.brange = [-0.05, 0.05]
    confd.crange = [0.95, 1.05]
    rescale = conf.link_id_rescale
    n_iters = conf.link_id_training_iters

    # how many times to sample. Actually it ends up being one less than specified
    num_times_sample = conf.link_id_mining_steps
    sampling_period = round(n_iters / num_times_sample)
    debug = conf.get('link_id_debug', False)

    net.eval()
    net = net.cuda()

    # Set mining distances to identical dummy values initially
    trk_data = []
    mining_dists = []
    for data, trk in zip(train_data, trk_p):
        ss, ee = trk.get_startendframes()
        tgt_id = np.array([r[1] for r in data])
        ss_t = ss[tgt_id]
        ee_t = ee[tgt_id]
        trk_data.append([ss_t, ee_t, tgt_id])
        t_dist = None
        n_tr = len(data)
        self_dist = np.ones(n_tr)
        overlap_dist = np.ones(n_tr)
        mining_dists.append([t_dist, overlap_dist, self_dist])

    # Create the dataset and dataloaders. Again seed is important!
    distort = True
    train_dset = lnk.id_dset(all_data, mining_dists, trk_data, confd, rescale, valid=False, distort=distort, debug=debug)
    n_workers = 10 if not debug else 0
    train_loader = torch.utils.data.DataLoader(train_dset, batch_size=bsz, pin_memory=True, num_workers=n_workers,
                                               worker_init_fn=lambda id: np.random.seed(id))
    train_iter = iter(train_loader)

    # Save example training images for debugging.
    ex_ims, ex_info = next(train_iter)
    ex_ims = ex_ims.numpy()

    for epoch in tqdm(range(n_iters)):

        if epoch % sampling_period == 0 and epoch > 0:
            # compute the mining data and recreate datasets and dataloaders with updated mining data
            net = net.eval()
            mining_dists = []
            for data, cur_trk_data in zip(all_data, trk_data):
                cur_dists = lnk.compute_mining_data(net, data, cur_trk_data, rescale, confd)

                mining_dists.append(cur_dists)

            # net = net.train()
            net = net.eval()
            del train_iter, train_loader, train_dset
            train_dset = lnk.id_dset(all_data, mining_dists, trk_data, confd, rescale, valid=True, distort=distort, debug=debug)
            train_loader = torch.utils.data.DataLoader(train_dset, batch_size=bsz, pin_memory=True, num_workers=10,
                                                       worker_init_fn=lambda id: np.random.seed(id * epoch))
            train_iter = iter(train_loader)

        if epoch % sampling_period ==0:
            n_mined = epoch//sampling_period
            for jj in range(40):
                cur_ims,data_info = next(train_iter)
                sel_d = np.random.randint(bsz)
                curd = data_info[0][0]
                sel_data = all_data[0][curd[1]]
                im1 = sel_data[0][curd[2]]
                im2 = sel_data[0][curd[3]]
                im3 = all_data[0][curd[4]][0][curd[5]]

                cur_ims = np.concatenate([im1,im2,im3],1)
                cur_ims = cur_ims.astype('uint8')
                out_im = f'{out_mined_dir}/round_{n_mined}_{jj}.png'
                cv2.imwrite(out_im,cur_ims)


        curims, data_info = next(train_iter)
        curims = curims.cuda()
        curims = curims.reshape((-1,) + curims.shape[2:])
        optimizer.zero_grad()
        output = net(curims)
        output = output.reshape((-1, 3) + output.shape[1:])
        output1, output2, output3 = output[:, 0], output[:, 1], output[:, 2]
        # output1, output2 are from the same tracklet so they should be close. output3 should be far from both output1 and output2

        l1 = criterion(output1, output2, 0)
        l2 = criterion(output1, output3, 1)
        l3 = criterion(output2, output3, 1)
        loss_contrastive = l1 + l2 + l3
        loss_contrastive.backward()
        optimizer.step()

        loss_history.append(loss_contrastive.item())


## Different errors committed by ID classifier

## setup
# mov_file = '/groups/branson/home/robiea/Projects_data/Labeler_APT/cx_GMR_SS00030_CsChr_RigC_20150826T144616/movie.ufmf'
# gtruth = '/groups/branson/home/kabram/temp/ar_social_fly_65F12_gt.trk'
# gtruth_tracklet = '/groups/branson/home/kabram/temp/ar_social_fly_65F12_gt_tracklet.trk'

mov_file = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629//movie.ufmf'
gtruth = '/groups/branson/home/bransonk/behavioranalysis/code/MABe2022/data/nochr_TrpA65F12_Unknown_RigB_20201212T163629/fixed_trx.mat'
gtruth_tracklet = '/groups/branson/home/kabram/temp/nochr_TrpA65F12_Unknown_RigB_20201212T163629_GT.trk'

id_wts = '/groups/branson/home/kabram/temp/ar_social_id_3_movs_idwts.p' # TODO

pure_tracklet = '/groups/branson/home/kabram/temp/ar_flytracker2_purelinked.trk'
id_link = None
ht_pts = [0,6]

out_dir = '/groups/branson/home/kabram/temp/id_errors_examples'
import TrkFile
import link_trajectories as lnk
from poseConfig import conf
import movies
import APT_interface as apt
from tqdm import tqdm
import torch
from torch import optim
import torch.nn.functional as F
import copy
import numpy as np
import cv2
import os

if not os.path.exists(out_dir):
    os.mkdir(out_dir)


trk_p = [TrkFile.Trk(tt) for tt in [pure_tracklet]]

# do id tracking

for k in trk_p[0].trkData['trkInfo']['params']:
    conf.__dict__[k] = trk_p[0].trkData['trkInfo']['params'][k]

conf.has_trx_file = False
conf.use_bbox_trx = False
conf.use_ht_trx = True
conf.img_dim = 3
conf.trx_align_theta = True
conf.link_id = True
# conf.ht_pts = (0,1)
conf.ht_pts = (0,6)
conf.imsz = [conf.multi_animal_crop_sz,conf.multi_animal_crop_sz]

trk_g = TrkFile.Trk(gtruth_tracklet)

## pure link GT file to create GT tracklet

# gt_tr = lnk.link_pure(trk_p[0],conf)
# gt_tr.save(gtruth_tracklet,saveformat='tracklet')

## Assign pure tracklet GT identity

npure = trk_p[0].ntargets
gt_i = np.ones(npure)*np.nan
tt = trk_p[0]
ss,ee = tt.get_startendframes()
for ndx in range(npure):
    sc = ss[ndx]; ec = ee[ndx]
    p = tt.gettargetframe(ndx,range(sc,ec+1))
    g = trk_g.getframe(range(sc,ec+1))
    dd = np.abs(np.sum(p-g,axis=(0,1,2)))
    if dd.min()<(ec-sc+1)*0.5:
        gt_i[ndx] = dd.argmin()


##
cap = movies.Movie(mov_file)
nfr = cap.get_n_frames()
cap.close()

trx_dict = apt.get_trx_info(pure_tracklet, conf, nfr,use_ht_pts=True)
trx = trx_dict['trx']

net = lnk.load_id_wts(id_wts)

net = net.eval()

# sample images for each tracklet and then find the embeddings for them
trk = trk_p[0]
ss, ee = trk.get_startendframes()

# For each tracklet chose n_per_trk random examples and the find their embedding. Ignore short tracklets
sel_tgt = np.where((ee - ss + 1) >=10)[0]
sel_ss = ss[sel_tgt];
sel_ee = ee[sel_tgt]
trk_info = list(zip(sel_tgt, sel_ss, sel_ee))
cur_data = lnk.read_ims_par(trx, trk_info, mov_file, conf)
gt_sel = gt_i[sel_tgt]

##
data = cur_data
ims = []
for curndx in range(len(data)):
    curims = data[curndx][0]
    ims.append(curims)

# Find the embeddings for the images
preds = lnk.tracklet_pred(ims, net, conf, rescale=1.)

dist_mat = lnk.get_id_dist_mat(preds)
dd_mat = np.linalg.norm(preds[None,:,None]-preds[:,None,:,None],axis=-1)

## Find pairs from same gt that are far


n_gt = trk_g.ntargets

same_err = 0
tot_count = 0
sel_pairs = None
for n in range(n_gt):
    cur_gt = np.where(gt_sel==n)[0]
    cur_d = dd_mat[cur_gt][:,cur_gt]
    same_err += np.count_nonzero(cur_d>1.)
    tot_count += cur_d.size
    err_p = np.array(np.where(cur_d>1.))[:,::100]
    err_p[0] = cur_gt[err_p[0]]
    err_p[1] = cur_gt[err_p[1]]
    if sel_pairs is None:
        sel_pairs = err_p
    else:
        sel_pairs = np.concatenate([sel_pairs,err_p],axis=1)

# same_err/tot_count = 0.6066

##

ex_im = []
for nx in range(10):
    rid = np.random.randint(sel_pairs.shape[1])
    rr = sel_pairs[:,rid]
    cur_im1 = ims[rr[0]][rr[2]]
    cur_im2 = ims[rr[1]][rr[3]]
    imi = np.concatenate([cur_im1,cur_im2],axis=1)
    ex_im.append(imi)

same_out_dir = out_dir + '/same_track_errors'
if not os.path.exists(same_out_dir):
    os.mkdir(same_out_dir)


for ndx,cur_im in enumerate(ex_im):
    cv2.imwrite(f'{same_out_dir}/{ndx}.png',cur_im.astype('uint8'))


## Error numbers using gt tracklets

trx_dict = apt.get_trx_info(gtruth_tracklet, conf, nfr,use_ht_pts=True)
trx = trx_dict['trx']

# sample images for each tracklet and then find the embeddings for them
trk = trk_g
ss, ee = trk.get_startendframes()

# For each tracklet chose n_per_trk random examples and the find their embedding. Ignore short tracklets
sel_tgt = np.where((ee - ss + 1) >=10)[0]
sel_ss = ss[sel_tgt];
sel_ee = ee[sel_tgt]
trk_info = list(zip(sel_tgt, sel_ss, sel_ee))
import copy
confg = copy.deepcopy(conf)
confg.link_id_tracklet_samples = 500
cur_data = lnk.read_ims_par(trx, trk_info, mov_file, confg)

data = cur_data
ims = []
for curndx in range(len(data)):
    curims = data[curndx][0]
    ims.append(curims)

# Find the embeddings for the images
preds = lnk.tracklet_pred(ims, net, conf, rescale=1.)

dist_mat = lnk.get_id_dist_mat(preds)
dd_mat = np.linalg.norm(preds[None,:,None]-preds[:,None,:,None],axis=-1)

n_gt = trk_g.ntargets

same_err = 0
tot_count = 0
sel_pairs = None
sel_pairs_succ = None
for cur_gt in range(n_gt):
    cur_d = dd_mat[cur_gt][cur_gt]
    same_err += np.count_nonzero(cur_d>1.)
    tot_count += cur_d.size
    err_pi = np.array(np.where(cur_d > 1.))
    err_p = np.zeros([4, err_pi.shape[1]])
    err_p[0] = cur_gt
    err_p[1] = cur_gt
    err_p[2:] = err_pi
    if sel_pairs is None:
        sel_pairs = err_p
    else:
        sel_pairs = np.concatenate([sel_pairs, err_p], axis=1)

    err_pi = np.array(np.where(cur_d < 1.))
    err_p = np.zeros([4, err_pi.shape[1]])
    err_p[0] = cur_gt
    err_p[1] = cur_gt
    err_p[2:] = err_pi
    if sel_pairs_succ is None:
        sel_pairs_succ = err_p
    else:
        sel_pairs_succ = np.concatenate([sel_pairs_succ, err_p], axis=1)

diff_err = 0
tot_count_diff = 0
sel_pairs_diff = None
sel_pairs_diff_succ = None
for i1 in range(n_gt):
    for i2 in range(i1+1,n_gt):
        cur_d = dd_mat[i1][i2]
        diff_err += np.count_nonzero(cur_d<1.)
        tot_count_diff += cur_d.size

        err_pi = np.array(np.where(cur_d<1.))
        err_p = np.zeros([4,err_pi.shape[1]])
        err_p[0] = i1
        err_p[1] = i2
        err_p[2:] = err_pi
        if sel_pairs_diff is None:
            sel_pairs_diff = err_p
        else:
            sel_pairs_diff = np.concatenate([sel_pairs_diff,err_p],axis=1)

        err_pi = np.array(np.where(cur_d>1.))
        err_p = np.zeros([4,err_pi.shape[1]])
        err_p[0] = i1
        err_p[1] = i2
        err_p[2:] = err_pi
        if sel_pairs_diff_succ is None:
            sel_pairs_diff_succ = err_p
        else:
            sel_pairs_diff_succ = np.concatenate([sel_pairs_diff_succ,err_p],axis=1)

sel_pairs_diff = sel_pairs_diff.astype('int')
diff_out_dir = out_dir + '/diff_track_errors'

##
cur_pairs = sel_pairs_succ
cur_out_dir = out_dir + '/same_tracks_success'

cur_pairs = sel_pairs
cur_out_dir = out_dir + '/same_tracks_errors'

cur_pairs = sel_pairs_diff
cur_out_dir = out_dir + '/diff_tracks_errors'

cur_pairs = sel_pairs_diff_succ
cur_out_dir = out_dir + '/diff_tracks_success'

cur_pairs = cur_pairs.astype('int')

ex_im = []
for nx in range(10):
    rid = np.random.randint(cur_pairs.shape[1])
    rr = cur_pairs[:,rid]
    cur_im1 = ims[rr[0]][rr[2]]
    cur_im2 = ims[rr[1]][rr[3]]
    imi = np.concatenate([cur_im1,cur_im2],axis=1)
    ex_im.append(imi)

if not os.path.exists(cur_out_dir):
    os.mkdir(cur_out_dir)


for ndx,cur_im in enumerate(ex_im):
    cv2.imwrite(f'{cur_out_dir}/{ndx}.png',cur_im.astype('uint8'))



# same_err/tot_count = 0.365
# diff_err/tot_count_diff = 0.025


##
n_gt = trk_g.ntargets
trx_dict = apt.get_trx_info(gtruth_tracklet, conf, nfr,use_ht_pts=True)
trx = trx_dict['trx']

import matplotlib.animation as animation
start_fr = 24500
frs = range(start_fr,start_fr+500)
# frs = range(5000,5050)
cap = movies.Movie(mov_file)


fr0 = cap.get_frame(start_fr)[0]

f = plt.figure()
f.set_size_inches([8,8])
ax = plt.imshow(fr0,'gray')
plt.axis('off')

im_dir = '/groups/branson/home/kabram/temp/id_mov_ims'
if not os.path.exists(im_dir):
    os.mkdir(im_dir)

cur_list = [[start_fr,ix] for ix in range(n_gt)]
ims0 = apt.create_batch_ims(cur_list, conf, cap, False, trx, None, use_bsize=False)
pred0 = lnk.tracklet_pred([ims0], net, conf, rescale=1.)[0]

cm = plt.get_cmap('PiYG',50)

def update(i):
    fr = cap.get_frame(i)[0]
    cur_list = [[i,ix] for ix in range(n_gt)]
    ims = apt.create_batch_ims(cur_list, conf, cap, False, trx, None, use_bsize=False)
    plt.cla()
    plt.tight_layout()
    plt.imshow(fr,'gray',vmin=0.0,vmax=255.0)
    pred = lnk.tracklet_pred([ims],net,conf,rescale=1.)[0]
    dd = np.linalg.norm(pred-pred0,axis=-1)
    for ix in range(n_gt):
        curx = trx[ix]['x'][0,i]
        cury = trx[ix]['y'][0,i]
        curd = 1-min(2.,dd[ix])/2
        curc = np.array([0.,1.,0.])*(1-curd) + np.array([1.,0.,0.])*curd
        plt.plot([curx-20,curx+20],[cury-50,cury-50],c=cm(int(curd*50)),lw=3)
    plt.axis('off')

    plt.savefig(f'{im_dir}/im_{i-frs[0]:05}.png')

for ii in frs:
    update(ii)

# ani = animation.FuncAnimation(f, update, frames=frs)
# savevidfile = os.path.join(im_dir,'id_dist.gif')
# print('Saving animation to file %s...'%savevidfile)
# writer = animation.PillowWriter(fps=30)
# ani.save(savevidfile,writer=writer)
