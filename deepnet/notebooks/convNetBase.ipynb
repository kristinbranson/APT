{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Mayank Jan 12 2016\n",
    "Paw detector modified from:\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import os,sys\n",
    "# import caffe\n",
    "import lmdb\n",
    "# import caffe.proto.caffe_pb2\n",
    "# from caffe.io import datum_to_array\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import cv2\n",
    "import tempfile\n",
    "import copy\n",
    "\n",
    "from batch_norm import batch_norm\n",
    "import myutils\n",
    "import PoseTools\n",
    "import localSetup\n",
    "\n",
    "# def conv2d(name, l_input, w, b):\n",
    "#     return tf.nn.relu(\n",
    "#         tf.nn.bias_add(\n",
    "#             tf.nn.conv2d(\n",
    "#                 l_input, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "#             ,b), \n",
    "#         name=name)\n",
    "\n",
    "def max_pool(name, l_input, k,s):\n",
    "    return tf.nn.max_pool(\n",
    "        l_input, ksize=[1, k, k, 1], strides=[1, s, s, 1], \n",
    "        padding='SAME', name=name)\n",
    "\n",
    "def norm(name, l_input, lsize=4):\n",
    "    return tf.nn.lrn(\n",
    "        l_input, lsize, bias=1.0, alpha=0.0001 , beta=0.75, \n",
    "        name=name)\n",
    "\n",
    "def upscale(name,l_input,sz):\n",
    "    l_out = tf.image.resize_nearest_neighbor(l_input,sz,name=name)\n",
    "    return l_out\n",
    "\n",
    "# def initNetConvWeights(conf):\n",
    "#     # Store layers weight & bias\n",
    "#     nfilt = conf.nfilt\n",
    "#     nfcfilt = conf.nfcfilt\n",
    "#     n_classes = conf.n_classes\n",
    "#     rescale = conf.rescale\n",
    "#     pool_scale = conf.pool_scale\n",
    "    \n",
    "# #     sz5 = int(math.ceil(conf.psz/rescale/pool_scale))\n",
    "#     sz5 = conf.psz\n",
    "#     weights = {\n",
    "#         'base0': initBaseWeights(nfilt),\n",
    "#         'base1': initBaseWeights(nfilt),\n",
    "#         'base2': initBaseWeights(nfilt),       \n",
    "#         'wd1': tf.Variable(tf.random_normal([sz5,sz5,conf.numscale*nfilt,nfcfilt],stddev=0.005)),\n",
    "#         'wd2': tf.Variable(tf.random_normal([1,1,nfcfilt, nfcfilt],stddev=0.005)),\n",
    "#         'wd3': tf.Variable(tf.random_normal([1,1,nfcfilt, n_classes],stddev=0.01)),\n",
    "#         'bd1': tf.Variable(tf.ones([nfcfilt])),\n",
    "#         'bd2': tf.Variable(tf.ones([nfcfilt])),\n",
    "#         'bd3': tf.Variable(tf.zeros([n_classes]))\n",
    "#     }\n",
    "#     return weights\n",
    "\n",
    "# def initBaseWeights(nfilt):\n",
    "    \n",
    "#     weights = {\n",
    "#     'wc1': tf.Variable(tf.random_normal([5, 5, 1, 48],stddev=0.01)),\n",
    "#     'wc2': tf.Variable(tf.random_normal([3, 3, 48, nfilt],stddev=0.01)),\n",
    "#     'wc3': tf.Variable(tf.random_normal([3, 3, nfilt, nfilt],stddev=0.01)),\n",
    "#     'wc4': tf.Variable(tf.random_normal([3, 3, nfilt, nfilt],stddev=0.01)),\n",
    "#     'wc5': tf.Variable(tf.random_normal([3, 3, nfilt, nfilt],stddev=0.01)),\n",
    "#     'bc1': tf.Variable(tf.zeros([48])),\n",
    "#     'bc2': tf.Variable(tf.ones([nfilt])),\n",
    "#     'bc3': tf.Variable(tf.ones([nfilt])),\n",
    "#     'bc4': tf.Variable(tf.ones([nfilt])),\n",
    "#     'bc5': tf.Variable(tf.ones([nfilt]))\n",
    "#     }\n",
    "#     return weights\n",
    "\n",
    "# def net_multi_base(X,_weights):\n",
    "    \n",
    "#     conv1 = conv2d('conv1', X, _weights['wc1'], _weights['bc1'])\n",
    "#     pool1 = max_pool('pool1', conv1, k=3,s=2)\n",
    "#     norm1 = norm('norm1', pool1, lsize=2)\n",
    "#     conv2 = conv2d('conv2', norm1, _weights['wc2'], _weights['bc2'])\n",
    "#     pool2 = max_pool('pool2', conv2, k=3,s=2)\n",
    "#     norm2 = norm('norm2', pool2, lsize=4)\n",
    "#     conv3 = conv2d('conv3', norm2, _weights['wc3'], _weights['bc3'])\n",
    "#     conv4 = conv2d('conv4', conv3, _weights['wc4'], _weights['bc4'])\n",
    "#     conv5 = conv2d('conv5', conv4, _weights['wc5'], _weights['bc5'])\n",
    "#     out_dict = {'conv1':conv1,'conv2':conv2,'conv3':conv3,\n",
    "#                 'conv4':conv4,'conv5':conv5,'pool1':pool1,\n",
    "#                 'pool2':pool2,'norm1':norm1,'norm2':norm2,\n",
    "#                }\n",
    "#     return conv5, out_dict\n",
    "\n",
    "def net_multi_base_named(X,nfilt,doBatchNorm,trainPhase):\n",
    "    inDim = X.get_shape()[3]\n",
    "    with tf.variable_scope('layer1'):\n",
    "        conv1 = conv_relu(X,[5, 5, inDim, 48],0.01,0,doBatchNorm,trainPhase)\n",
    "        pool1 = max_pool('pool1', conv1, k=3,s=2)\n",
    "        norm1 = norm('norm1', pool1, lsize=2)\n",
    "    \n",
    "    with tf.variable_scope('layer2'):\n",
    "        conv2 = conv_relu(norm1,[3,3,48,nfilt],0.01,1,doBatchNorm,trainPhase)\n",
    "        pool2 = max_pool('pool2', conv2, k=3,s=2)\n",
    "        norm2 = norm('norm2', pool2, lsize=4)\n",
    "            \n",
    "    with tf.variable_scope('layer3'):\n",
    "        conv3 = conv_relu(norm2,[3,3,nfilt,nfilt],0.01,1,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('layer4'):\n",
    "        conv4 = conv_relu(conv3,[3,3,nfilt,nfilt],0.01,1,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('layer5'):\n",
    "        conv5 = conv_relu(conv4,[3,3,nfilt,nfilt],0.01,1,doBatchNorm,trainPhase)\n",
    "        \n",
    "    out_dict = {'conv1':conv1,'conv2':conv2,'conv3':conv3,\n",
    "                'conv4':conv4,'conv5':conv5,'pool1':pool1,\n",
    "                'pool2':pool2,'norm1':norm1,'norm2':norm2,\n",
    "               }\n",
    "    return conv5,out_dict\n",
    "        \n",
    "\n",
    "def net_multi_conv(X0,X1,X2,_dropout,conf,doBatchNorm,trainPhase):\n",
    "    imsz = conf.imsz; rescale = conf.rescale\n",
    "    pool_scale = conf.pool_scale\n",
    "    nfilt = conf.nfilt\n",
    "    \n",
    "    #     conv5_0,base_dict_0 = net_multi_base(X0,_weights['base0'])\n",
    "    #     conv5_1,base_dict_1 = net_multi_base(X1,_weights['base1'])\n",
    "    #     conv5_2,base_dict_2 = net_multi_base(X2,_weights['base2'])\n",
    "    with tf.variable_scope('scale0'):\n",
    "        conv5_0,base_dict_0 = net_multi_base_named(X0,nfilt,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('scale1'):\n",
    "        conv5_1,base_dict_1 = net_multi_base_named(X1,nfilt,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('scale2'):\n",
    "        conv5_2,base_dict_2 = net_multi_base_named(X2,nfilt,doBatchNorm,trainPhase)\n",
    "\n",
    "    sz0 = int(math.ceil(float(imsz[0])/pool_scale/rescale))\n",
    "    sz1 = int(math.ceil(float(imsz[1])/pool_scale/rescale))\n",
    "    conv5_1_up = upscale('5_1',conv5_1,[sz0,sz1])\n",
    "    conv5_2_up = upscale('5_2',conv5_2,[sz0,sz1])\n",
    "\n",
    "    # crop lower res layers to match higher res size\n",
    "    conv5_0_sz = tf.Tensor.get_shape(conv5_0).as_list()\n",
    "    conv5_1_sz = tf.Tensor.get_shape(conv5_1_up).as_list()\n",
    "    crop_0 = int((sz0-conv5_0_sz[1])/2)\n",
    "    crop_1 = int((sz1-conv5_0_sz[2])/2)\n",
    "\n",
    "    curloc = [0,crop_0,crop_1,0]\n",
    "    patchsz = tf.to_int32([-1,conv5_0_sz[1],conv5_0_sz[2],-1])\n",
    "    conv5_1_up = tf.slice(conv5_1_up,curloc,patchsz)\n",
    "    conv5_2_up = tf.slice(conv5_2_up,curloc,patchsz)\n",
    "    conv5_1_final_sz = tf.Tensor.get_shape(conv5_1_up).as_list()\n",
    "#     print(\"Initial lower res layer size %s\"%(', '.join(map(str,conv5_1_sz))))\n",
    "#     print(\"Initial higher res layer size %s\"%(', '.join(map(str,conv5_0_sz))))\n",
    "#     print(\"Crop start lower res layer at %s\"%(', '.join(map(str,curloc))))\n",
    "#     print(\"Final size of lower res layer %s\"%(', '.join(map(str,conv5_1_final_sz))))\n",
    "\n",
    "\n",
    "    conv5_cat = tf.concat(3,[conv5_0,conv5_1_up,conv5_2_up])\n",
    "    \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "#     conv6 = conv2d('conv6',conv5_cat,_weights['wd1'],_weights['bd1']) \n",
    "#     conv6 = tf.nn.dropout(conv6,_dropout)\n",
    "#     conv7 = conv2d('conv7',conv6,_weights['wd2'],_weights['bd2']) \n",
    "#     conv7 = tf.nn.dropout(conv7,_dropout)\n",
    "\n",
    "    with tf.variable_scope('layer6'):\n",
    "        conv6 = conv_relu(conv5_cat,\n",
    "                         [conf.psz,conf.psz,conf.numscale*nfilt,conf.nfcfilt],\n",
    "                          0.005,1,doBatchNorm,trainPhase) \n",
    "        if not doBatchNorm:\n",
    "            conv6 = tf.nn.dropout(conv6,_dropout,\n",
    "                              [conf.batch_size,1,1,conf.nfcfilt])\n",
    "\n",
    "    with tf.variable_scope('layer7'):\n",
    "        conv7 = conv_relu(conv6,[1,1,conf.nfcfilt,conf.nfcfilt],\n",
    "                          0.005,1,doBatchNorm,trainPhase) \n",
    "        if not doBatchNorm:\n",
    "            conv7 = tf.nn.dropout(conv7,_dropout,\n",
    "                                  [conf.batch_size,1,1,conf.nfcfilt])\n",
    "\n",
    "# Output, class prediction\n",
    "#     out = tf.nn.bias_add(tf.nn.conv2d(\n",
    "#             conv7, _weights['wd3'], \n",
    "#             strides=[1, 1, 1, 1], padding='SAME'),_weights['bd3'])\n",
    "\n",
    "    with tf.variable_scope('layer8'):\n",
    "        l8_weights = tf.get_variable(\"weights\", [1,1,conf.nfcfilt,conf.n_classes],\n",
    "            initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        l8_biases = tf.get_variable(\"biases\", conf.n_classes,\n",
    "            initializer=tf.constant_initializer(0))\n",
    "        out = tf.nn.conv2d(conv7, l8_weights,\n",
    "            strides=[1, 1, 1, 1], padding='SAME') + l8_biases\n",
    "#   No batch norm for the output layer.\n",
    "\n",
    "    out_dict = {'base_dict_0':base_dict_0,\n",
    "                'base_dict_1':base_dict_1,\n",
    "                'base_dict_2':base_dict_2,\n",
    "                'conv6':conv6,\n",
    "                'conv7':conv7,\n",
    "               }\n",
    "    \n",
    "    return out,out_dict\n",
    "\n",
    "\n",
    "def net_multi_conv_reg(X0,X1,X2,_dropout,conf,doBatchNorm,trainPhase):\n",
    "    imsz = conf.imsz; rescale = conf.rescale\n",
    "    pool_scale = conf.pool_scale\n",
    "    nfilt = conf.nfilt\n",
    "    \n",
    "    #     conv5_0,base_dict_0 = net_multi_base(X0,_weights['base0'])\n",
    "    #     conv5_1,base_dict_1 = net_multi_base(X1,_weights['base1'])\n",
    "    #     conv5_2,base_dict_2 = net_multi_base(X2,_weights['base2'])\n",
    "    with tf.variable_scope('scale0'):\n",
    "        conv5_0,base_dict_0 = net_multi_base_named(X0,nfilt,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('scale1'):\n",
    "        conv5_1,base_dict_1 = net_multi_base_named(X1,nfilt,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('scale2'):\n",
    "        conv5_2,base_dict_2 = net_multi_base_named(X2,nfilt,doBatchNorm,trainPhase)\n",
    "\n",
    "    sz0 = int(math.ceil(float(imsz[0])/pool_scale/rescale))\n",
    "    sz1 = int(math.ceil(float(imsz[1])/pool_scale/rescale))\n",
    "    conv5_1_up = upscale('5_1',conv5_1,[sz0,sz1])\n",
    "    conv5_2_up = upscale('5_2',conv5_2,[sz0,sz1])\n",
    "\n",
    "    # crop lower res layers to match higher res size\n",
    "    conv5_0_sz = tf.Tensor.get_shape(conv5_0).as_list()\n",
    "    conv5_1_sz = tf.Tensor.get_shape(conv5_1_up).as_list()\n",
    "    crop_0 = int((sz0-conv5_0_sz[1])/2)\n",
    "    crop_1 = int((sz1-conv5_0_sz[2])/2)\n",
    "\n",
    "    curloc = [0,crop_0,crop_1,0]\n",
    "    patchsz = tf.to_int32([-1,conv5_0_sz[1],conv5_0_sz[2],-1])\n",
    "    conv5_1_up = tf.slice(conv5_1_up,curloc,patchsz)\n",
    "    conv5_2_up = tf.slice(conv5_2_up,curloc,patchsz)\n",
    "    conv5_1_final_sz = tf.Tensor.get_shape(conv5_1_up).as_list()\n",
    "#     print(\"Initial lower res layer size %s\"%(', '.join(map(str,conv5_1_sz))))\n",
    "#     print(\"Initial higher res layer size %s\"%(', '.join(map(str,conv5_0_sz))))\n",
    "#     print(\"Crop start lower res layer at %s\"%(', '.join(map(str,curloc))))\n",
    "#     print(\"Final size of lower res layer %s\"%(', '.join(map(str,conv5_1_final_sz))))\n",
    "\n",
    "\n",
    "    conv5_cat = tf.concat(3,[conv5_0,conv5_1_up,conv5_2_up])\n",
    "    \n",
    "    # Reshape conv5 output to fit dense layer input\n",
    "#     conv6 = conv2d('conv6',conv5_cat,_weights['wd1'],_weights['bd1']) \n",
    "#     conv6 = tf.nn.dropout(conv6,_dropout)\n",
    "#     conv7 = conv2d('conv7',conv6,_weights['wd2'],_weights['bd2']) \n",
    "#     conv7 = tf.nn.dropout(conv7,_dropout)\n",
    "\n",
    "    with tf.variable_scope('layer6'):\n",
    "        conv6 = conv_relu(conv5_cat,\n",
    "                         [conf.psz,conf.psz,conf.numscale*nfilt,conf.nfcfilt],\n",
    "                          0.005,1,doBatchNorm,trainPhase) \n",
    "        if not doBatchNorm:\n",
    "            conv6 = tf.nn.dropout(conv6,_dropout,\n",
    "                              [conf.batch_size,1,1,conf.nfcfilt])\n",
    "\n",
    "    with tf.variable_scope('layer7'):\n",
    "        conv7 = conv_relu(conv6,[1,1,conf.nfcfilt,conf.nfcfilt],\n",
    "                          0.005,1,doBatchNorm,trainPhase) \n",
    "        if not doBatchNorm:\n",
    "            conv7 = tf.nn.dropout(conv7,_dropout,\n",
    "                                  [conf.batch_size,1,1,conf.nfcfilt])\n",
    "\n",
    "# Output, class prediction\n",
    "#     out = tf.nn.bias_add(tf.nn.conv2d(\n",
    "#             conv7, _weights['wd3'], \n",
    "#             strides=[1, 1, 1, 1], padding='SAME'),_weights['bd3'])\n",
    "\n",
    "    with tf.variable_scope('layer8'):\n",
    "        l8_weights = tf.get_variable(\"weights\", [1,1,conf.nfcfilt,conf.n_classes],\n",
    "            initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        l8_biases = tf.get_variable(\"biases\", conf.n_classes,\n",
    "            initializer=tf.constant_initializer(0))\n",
    "        out = tf.nn.conv2d(conv7, l8_weights,\n",
    "            strides=[1, 1, 1, 1], padding='SAME') + l8_biases\n",
    "\n",
    "    with tf.variable_scope('layer8_x'):\n",
    "        l8x_weights = tf.get_variable(\"weights\", [1,1,conf.nfcfilt,conf.n_classes],\n",
    "            initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        l8x_biases = tf.get_variable(\"biases\", conf.n_classes,\n",
    "            initializer=tf.constant_initializer(0))\n",
    "        out_x = tf.nn.conv2d(conv7, l8x_weights,\n",
    "            strides=[1, 1, 1, 1], padding='SAME') + l8x_biases\n",
    "\n",
    "    with tf.variable_scope('layer8_y'):\n",
    "        l8y_weights = tf.get_variable(\"weights\", [1,1,conf.nfcfilt,conf.n_classes],\n",
    "            initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        l8y_biases = tf.get_variable(\"biases\", conf.n_classes,\n",
    "            initializer=tf.constant_initializer(0))\n",
    "        out_y = tf.nn.conv2d(conv7, l8y_weights,\n",
    "            strides=[1, 1, 1, 1], padding='SAME') + l8y_biases\n",
    "        \n",
    "    out_dict = {'base_dict_0':base_dict_0,\n",
    "                'base_dict_1':base_dict_1,\n",
    "                'base_dict_2':base_dict_2,\n",
    "                'conv6':conv6,\n",
    "                'conv7':conv7,\n",
    "               }\n",
    "    \n",
    "    return out, out_x, out_y, out_dict\n",
    "\n",
    "\n",
    "\n",
    "def createPlaceHolders(imsz,rescale,scale,pool_scale,n_classes,inDim=1):\n",
    "#     imsz = conf.imsz\n",
    "    # tf Graph input\n",
    "    keep_prob = tf.placeholder(tf.float32,name='dropout') # dropout(keep probability)\n",
    "    x0 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/rescale,\n",
    "                                     imsz[1]/rescale,inDim],name='x0')\n",
    "    x1 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/scale/rescale,\n",
    "                                     imsz[1]/scale/rescale,inDim],name='x1')\n",
    "    x2 = tf.placeholder(tf.float32, [None, \n",
    "                                     imsz[0]/scale/scale/rescale,\n",
    "                                     imsz[1]/scale/scale/rescale,inDim],name='x2')\n",
    "\n",
    "    lsz0,lsz1 = findPredSize(imsz,rescale,pool_scale)\n",
    "    y = tf.placeholder(tf.float32, [None, lsz0,lsz1,n_classes],'limg')\n",
    "    return x0,x1,x2,y,keep_prob\n",
    "\n",
    "def findPredSize(imsz,rescale,pool_scale):\n",
    "    lsz0 = int(math.ceil(float(imsz[0])/pool_scale/rescale))\n",
    "    lsz1 = int(math.ceil(float(imsz[1])/pool_scale/rescale))\n",
    "    return lsz0, lsz1\n",
    "\n",
    "def conv_relu(X, kernel_shape, conv_std,bias_val,doBatchNorm,trainPhase):\n",
    "    weights = tf.get_variable(\"weights\", kernel_shape,\n",
    "        initializer=tf.random_normal_initializer(stddev=conv_std))\n",
    "    biases = tf.get_variable(\"biases\", kernel_shape[-1],\n",
    "        initializer=tf.constant_initializer(bias_val))\n",
    "    conv = tf.nn.conv2d(X, weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    if doBatchNorm:\n",
    "        conv = batch_norm(conv,trainPhase)\n",
    "    return tf.nn.relu(conv + biases)\n",
    "\n",
    "\n",
    "def fine_base(X,conf,insize,doBatchNorm,trainPhase):\n",
    "    fsz = conf.fine_flt_sz\n",
    "    fine_nfilt = conf.fine_nfilt\n",
    "    with tf.variable_scope(\"fine_1\"):\n",
    "        conv1 = conv_relu(X, [fsz, fsz, insize, fine_nfilt],\n",
    "                          0.05,1,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope(\"fine_2\"):\n",
    "        conv2 = conv_relu(conv1, [fsz, fsz, fine_nfilt, fine_nfilt],\n",
    "                          0.05,1,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope(\"fine_3\"):\n",
    "        conv3 = conv_relu(conv2, [fsz, fsz, fine_nfilt, fine_nfilt/2],\n",
    "                          0.05,1,doBatchNorm,trainPhase)\n",
    "    return conv3\n",
    "\n",
    "    \n",
    "\n",
    "def fineNetwork(fineIn1_1,fineIn1_2,fineIn2_1,fineIn2_2,\n",
    "                conf,doBatchNorm,trainPhase):\n",
    "\n",
    "#     fsz = conf.fine_sz\n",
    "#     fineIn1_2_up = upscale('fine1_2',fineIn1_2,[fsz,fsz])\n",
    "#     fineIn2_1_up = upscale('fine2_1',fineIn2_1,[fsz,fsz])\n",
    "#     fineIn2_2_up = upscale('fine2_2',fineIn2_2,[fsz,fsz])\n",
    "#     fineIn7_up   = upscale('fine7',fineIn7,[fsz,fsz])\n",
    "    with tf.variable_scope('1_1'):\n",
    "        fine1_1 = fine_base(fineIn1_1,conf,48,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('1_2'):\n",
    "        fine1_2 = fine_base(fineIn1_2,conf,conf.nfilt,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('2_1'):\n",
    "        fine2_1 = fine_base(fineIn2_1,conf,48,doBatchNorm,trainPhase)\n",
    "    with tf.variable_scope('2_2'):\n",
    "        fine2_2 = fine_base(fineIn2_2,conf,conf.nfilt,doBatchNorm,trainPhase)\n",
    "\n",
    "    fsz = conf.fine_sz\n",
    "    fine1_2_up = upscale('fine1_2',fine1_2,[fsz,fsz])\n",
    "    fine2_1_up = upscale('fine2_1',fine2_1,[fsz,fsz])\n",
    "    fine2_2_up = upscale('fine2_2',fine2_2,[fsz,fsz])\n",
    "    fineSum = tf.add_n([fine1_1,fine1_2_up,fine2_1_up,fine2_2_up])\n",
    "#     fineSum = tf.add_n([fine1_1,fine1_2,fine2_1,fine2_2,fine7])\n",
    "    # for fine apparently adding is better than concatenating!!\n",
    "#     conv5_cat = tf.concat(3,[fine1_1,fine1_2_up,fine2_1_up,fine2_2_up])\n",
    "    return fineSum\n",
    "\n",
    "def fineOut(fineIn1_1,fineIn1_2,fineIn2_1,fineIn2_2,fineIn7,conf,doBatchNorm,trainPhase):\n",
    "    inter = []\n",
    "    with tf.variable_scope('fine_siamese') as scope:\n",
    "        tvar = fineNetwork(fineIn1_1[0], fineIn1_2[0],\n",
    "                           fineIn2_1[0], fineIn2_2[0],\n",
    "                           fineIn7[0], conf, doBatchNorm, \n",
    "                           trainPhase)\n",
    "        inter.append(tvar)\n",
    "        scope.reuse_variables()\n",
    "        for ndx in range(1,len(fineIn1_1)):\n",
    "            tvar = fineNetwork(fineIn1_1[ndx], fineIn1_2[ndx],\n",
    "                               fineIn2_1[ndx], fineIn2_2[ndx],\n",
    "                               fineIn7[ndx], conf, doBatchNorm, \n",
    "                               trainPhase)\n",
    "            inter.append(tvar)\n",
    "\n",
    "    fineLast = []\n",
    "    for ndx in range(len(fineIn1_1)):\n",
    "        with tf.variable_scope('point_' + str(ndx)):\n",
    "            weights = tf.get_variable(\"weights\", [1,1,conf.fine_nfilt/2,1],\n",
    "                initializer=tf.random_normal_initializer(stddev=0.05))\n",
    "            biases = tf.get_variable(\"biases\", 1,\n",
    "                initializer=tf.constant_initializer(0))\n",
    "            conv = tf.nn.conv2d(inter[ndx], weights,\n",
    "                strides=[1, 1, 1, 1], padding='SAME')\n",
    "            fineLast.append(conv + biases)\n",
    "\n",
    "    out = tf.concat(3,fineLast)\n",
    "    return out\n",
    "\n",
    "def extractPatches(layer,out,conf,scale,outscale):\n",
    "    hsz = conf.fine_sz/scale/2\n",
    "    padsz = tf.constant([[0,0],[hsz, hsz],[hsz,hsz],[0,0]])\n",
    "    patchsz = tf.to_int32([conf.fine_sz/scale,conf.fine_sz/scale,-1])\n",
    "\n",
    "    patches = []\n",
    "    maxloc = PoseTools.argmax2d(out)*outscale\n",
    "    padlayer = tf.pad(layer,padsz)\n",
    "    for inum in range(conf.batch_size):\n",
    "        curpatches = []\n",
    "        for ndx in range(conf.n_classes):\n",
    "            curloc = tf.concat(0,[tf.squeeze(maxloc[:,inum,ndx]),[0]])\n",
    "            curpatches.append(tf.slice(padlayer[inum,:,:,:],curloc,patchsz))\n",
    "        patches.append(tf.pack(curpatches))\n",
    "    return tf.pack(patches)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
