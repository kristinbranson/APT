{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import localSetup\n",
    "import scipy.io as sio\n",
    "import os,sys\n",
    "import myutils\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "from cvc import cvc\n",
    "import math\n",
    "import lmdb\n",
    "# import caffe\n",
    "from random import randint,sample\n",
    "import pickle\n",
    "import h5py\n",
    "import errno\n",
    "import PoseTools\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLocalDirs(conf):\n",
    "    L = h5py.File(conf.labelfile,'r')\n",
    "    localdirs = [u''.join(unichr(c) for c in L[jj]) for jj in conf.getexplist(L)]\n",
    "    seldirs = [True]*len(localdirs)\n",
    "    L.close()\n",
    "    return localdirs,seldirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createValdata(conf,force=False):\n",
    "    \n",
    "    outfile = os.path.join(conf.cachedir,conf.valdatafilename)\n",
    "    if ~force & os.path.isfile(outfile):\n",
    "        return\n",
    "\n",
    "    print('Creating val data %s!'%outfile)\n",
    "    localdirs,seldirs = findLocalDirs(conf)\n",
    "    nexps = len(seldirs)\n",
    "    isval = sample(range(nexps),int(nexps*conf.valratio))\n",
    "    try:\n",
    "        os.makedirs(conf.cachedir)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "    with open(outfile,'w') as f:\n",
    "        pickle.dump([isval,localdirs,seldirs],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadValdata(conf):\n",
    "    \n",
    "    outfile = os.path.join(conf.cachedir,conf.valdatafilename)\n",
    "    assert os.path.isfile(outfile),\"valdatafile doesn't exist\"\n",
    "\n",
    "    with open(outfile,'r') as f:\n",
    "        isval,localdirs,seldirs = pickle.load(f)\n",
    "    return isval,localdirs,seldirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMovieLists(conf):\n",
    "    isval,localdirs,seldirs = loadValdata(conf)\n",
    "    trainexps = []; valexps = []\n",
    "    for ndx in range(len(localdirs)):\n",
    "        if not seldirs[ndx]:\n",
    "            continue\n",
    "        if isval.count(ndx):\n",
    "            valexps.append(localdirs[ndx])\n",
    "        else:\n",
    "            trainexps.append(localdirs[ndx])\n",
    "    \n",
    "    return trainexps, valexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def createDatum(curp,label):\n",
    "#     datum = caffe.proto.caffe_pb2.Datum()\n",
    "#     datum.channels = curp.shape[0]\n",
    "#     datum.height = curp.shape[1]\n",
    "#     datum.width = curp.shape[2]\n",
    "#     datum.data = curp.tostring()  # or .tobytes() if numpy >= 1.9\n",
    "#     datum.label = label\n",
    "#     return datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createID(expname,curloc,fnum,imsz):\n",
    "    for x in curloc: \n",
    "        assert x[0] >= 0,\"x value %d is less than 0\" %x[0]\n",
    "        assert x[1] >= 0,\"y value %d is less than 0\" %x[1]\n",
    "        assert x[0] < imsz[1],\"x value %d is greater than imsz %d\"%(x[0],imsz[1])\n",
    "        assert x[1] < imsz[0],\"y value %d is greater than imsz %d\"%(x[1],imsz[0])\n",
    "    \n",
    "    xstr = '_'.join([str(x[0]) for x in curloc])\n",
    "    ystr = '_'.join([str(x[1]) for x in curloc])\n",
    "    \n",
    "    str_id = '{:08d}:{}:x{}:y{}:t{:d}'.format(randint(0,1e8),\n",
    "           expname,xstr,ystr,fnum)\n",
    "    return str_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decodeID(keystr):\n",
    "    vv = re.findall('(\\d+):(.*):x(.*):y(.*):t(\\d+)',keystr)[0]\n",
    "    xlocs = [int(x) for x in vv[2].split('_')]\n",
    "    ylocs = [int(x) for x in vv[3].split('_')]\n",
    "    locs = zip(xlocs,ylocs)\n",
    "    return vv[1],locs,int(vv[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitizelocs(locs):\n",
    "    nlocs = np.array(locs).astype('float')\n",
    "    nlocs[nlocs<0] = np.nan\n",
    "    return nlocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def createHoldoutData(conf):\n",
    "#     #Split the val data in hold out data for mrf training.\n",
    "#     isval,localdirs,seldirs = loadValdata(conf)\n",
    "#     n_ho = min(max(int(len(isval)*conf.holdoutratio),1),len(isval)-1)\n",
    "# #     ho_train = isval[0:n_ho]\n",
    "# #     ho_test = isval[(n_ho+1):]\n",
    "\n",
    "#     L = h5py.File(conf.labelfile,'r')\n",
    "#     pts = np.array(L['pts'])\n",
    "#     ts = np.array(L['ts']).squeeze().astype('int')\n",
    "#     expid = np.array(L['expidx']).squeeze().astype('int')\n",
    "#     view = conf.view\n",
    "#     traincount = 0; testcount = 0\n",
    "    \n",
    "#     psz = conf.sel_sz\n",
    "#     map_size = 100000*conf.imsz[0]*conf.imsz[1]*8\n",
    "    \n",
    "#     trainlmdbfilename =os.path.join(conf.cachedir,conf.holdouttrain)\n",
    "#     testlmdbfilename =os.path.join(conf.cachedir,conf.holdouttest)\n",
    "#     if os.path.isdir(trainlmdbfilename):\n",
    "#         shutil.rmtree(trainlmdbfilename)\n",
    "#     if os.path.isdir(testlmdbfilename):\n",
    "#         shutil.rmtree(testlmdbfilename)\n",
    "    \n",
    "#     trainenv = lmdb.open(trainlmdbfilename, map_size=map_size)\n",
    "#     testenv = lmdb.open(testlmdbfilename, map_size=map_size)\n",
    "\n",
    "    \n",
    "#     with trainenv.begin(write=True) as traintxn,testenv.begin(write=True) as testtxn:\n",
    "\n",
    "#         for ndx,dirname in enumerate(localdirs):\n",
    "\n",
    "#             if not seldirs[ndx]:\n",
    "#                 continue\n",
    "#             if not isval.count(ndx):\n",
    "#                 continue\n",
    "\n",
    "#             expname = conf.getexpname(dirname)\n",
    "#             frames = np.where(expid == (ndx + 1))[0]\n",
    "#             curdir = os.path.dirname(localdirs[ndx])\n",
    "#             cap = cv2.VideoCapture(localdirs[ndx])\n",
    "            \n",
    "#             curtxn = testtxn if isval.index(ndx)>=n_ho else traintxn\n",
    "                \n",
    "#             for curl in frames:\n",
    "\n",
    "#                 fnum = ts[curl]\n",
    "#                 if fnum > cap.get(cvc.FRAME_COUNT):\n",
    "#                     if fnum > cap.get(cvc.FRAME_COUNT)+1:\n",
    "#                         raise ValueError('Accessing frames beyond ' + \n",
    "#                                          'the length of the video for' + \n",
    "#                                          ' {} expid {:d} '.format(expname,ndx) + \n",
    "#                                          ' at t {:d}'.format(fnum)\n",
    "#                                         )\n",
    "#                     continue\n",
    "#                 framein = myutils.readframe(cap,fnum-1)\n",
    "#                 cloc = conf.cropLoc[tuple(framein.shape[0:2])]\n",
    "#                 framein = PoseTools.cropImages(framein,conf)\n",
    "#                 framein = framein[:,:,0:1]\n",
    " \n",
    "#                 curloc = np.round(pts[curl,:,view,:]).astype('int')\n",
    "#                 curloc[:,0] = curloc[:,0] - cloc[1]  # ugh, the nasty x-y business.\n",
    "#                 curloc[:,1] = curloc[:,1] - cloc[0]\n",
    "                \n",
    "#                 datum = createDatum(framein,1)\n",
    "#                 str_id = createID(expname,curloc,fnum,conf.imsz)\n",
    "#                 curtxn.put(str_id.encode('ascii'), datum.SerializeToString())\n",
    "\n",
    "#                 if isval.index(ndx)>=n_ho:\n",
    "#                     testcount+=1\n",
    "#                 else:\n",
    "#                     traincount+=1\n",
    "                    \n",
    "#             cap.release() # close the movie handles\n",
    "#             print('Done %d of %d movies, train:%d test:%d' % (ndx,len(localdirs),traincount,testcount))\n",
    "#     trainenv.close() # close the database\n",
    "#     testenv.close()\n",
    "#     print('%d,%d number of pos examples added to the train db and test db' %(traincount,testcount))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def createDB(conf):\n",
    "\n",
    "#     L = h5py.File(conf.labelfile,'r')\n",
    "#     pts = np.array(L['pts'])\n",
    "#     ts = np.array(L['ts']).squeeze().astype('int')\n",
    "#     expid = np.array(L['expidx']).squeeze().astype('int')\n",
    "#     view = conf.view\n",
    "#     count = 0; valcount = 0\n",
    "    \n",
    "#     psz = conf.sel_sz\n",
    "#     map_size = 100000*conf.imsz[0]*conf.imsz[1]*8\n",
    "    \n",
    "#     createValdata(conf)\n",
    "#     isval,localdirs,seldirs = loadValdata(conf)\n",
    "    \n",
    "#     lmdbfilename =os.path.join(conf.cachedir,conf.trainfilename)\n",
    "#     vallmdbfilename =os.path.join(conf.cachedir,conf.valfilename)\n",
    "#     if os.path.isdir(lmdbfilename):\n",
    "#         shutil.rmtree(lmdbfilename)\n",
    "#     if os.path.isdir(vallmdbfilename):\n",
    "#         shutil.rmtree(vallmdbfilename)\n",
    "    \n",
    "#     env = lmdb.open(lmdbfilename, map_size=map_size)\n",
    "#     valenv = lmdb.open(vallmdbfilename, map_size=map_size)\n",
    "\n",
    "    \n",
    "#     with env.begin(write=True) as txn,valenv.begin(write=True) as valtxn:\n",
    "\n",
    "#         for ndx,dirname in enumerate(localdirs):\n",
    "#             if not seldirs[ndx]:\n",
    "#                 continue\n",
    "\n",
    "#             expname = conf.getexpname(dirname)\n",
    "#             frames = np.where(expid == (ndx + 1))[0]\n",
    "#             curdir = os.path.dirname(localdirs[ndx])\n",
    "#             cap = cv2.VideoCapture(localdirs[ndx])\n",
    "            \n",
    "#             curtxn = valtxn if isval.count(ndx) else txn\n",
    "                \n",
    "#             for curl in frames:\n",
    "\n",
    "#                 fnum = ts[curl]\n",
    "#                 if fnum > cap.get(cvc.FRAME_COUNT):\n",
    "#                     if fnum > cap.get(cvc.FRAME_COUNT)+1:\n",
    "#                         raise ValueError('Accessing frames beyond ' + \n",
    "#                                          'the length of the video for' + \n",
    "#                                          ' {} expid {:d} '.format(expname,ndx) + \n",
    "#                                          ' at t {:d}'.format(fnum)\n",
    "#                                         )\n",
    "#                     continue\n",
    "#                 framein = myutils.readframe(cap,fnum-1)\n",
    "#                 cloc = conf.cropLoc[tuple(framein.shape[0:2])]\n",
    "#                 framein = PoseTools.cropImages(framein,conf)\n",
    "#                 framein = framein[:,:,0:1]\n",
    " \n",
    "#                 curloc = np.round(pts[curl,:,view,:]).astype('int')\n",
    "#                 curloc[:,0] = curloc[:,0] - cloc[1]  # ugh, the nasty x-y business.\n",
    "#                 curloc[:,1] = curloc[:,1] - cloc[0]\n",
    "                \n",
    "#                 datum = createDatum(framein,1)\n",
    "#                 str_id = createID(expname,curloc,fnum,conf.imsz)\n",
    "#                 curtxn.put(str_id.encode('ascii'), datum.SerializeToString())\n",
    "\n",
    "#                 if isval.count(ndx):\n",
    "#                     valcount+=1\n",
    "#                 else:\n",
    "#                     count+=1\n",
    "                    \n",
    "#             cap.release() # close the movie handles\n",
    "#             print('Done %d of %d movies, count:%d val:%d' % (ndx,len(localdirs),count,valcount))\n",
    "#     env.close() # close the database\n",
    "#     valenv.close()\n",
    "#     print('%d,%d number of pos examples added to the db and valdb' %(count,valcount))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    if not isinstance(value,(list,np.ndarray)):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    if not isinstance(value,list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    if not isinstance(value,(list,np.ndarray)):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTFRecord(conf):\n",
    "\n",
    "    L = h5py.File(conf.labelfile,'r')\n",
    "    pts = np.array(L['pts'])\n",
    "    ts = np.array(L['ts']).squeeze().astype('int')\n",
    "    expid = np.array(L['expidx']).squeeze().astype('int')\n",
    "    view = conf.view\n",
    "    count = 0; valcount = 0\n",
    "    \n",
    "    psz = conf.sel_sz\n",
    "    \n",
    "    createValdata(conf)\n",
    "    isval,localdirs,seldirs = loadValdata(conf)\n",
    "    \n",
    "    trainfilename =os.path.join(conf.cachedir,conf.trainfilename)\n",
    "    valfilename =os.path.join(conf.cachedir,conf.valfilename)\n",
    "    \n",
    "    env = tf.python_io.TFRecordWriter(trainfilename+'.tfrecords')\n",
    "    valenv = tf.python_io.TFRecordWriter(valfilename+'.tfrecords')\n",
    "\n",
    "    \n",
    "    for ndx,dirname in enumerate(localdirs):\n",
    "        if not seldirs[ndx]:\n",
    "            continue\n",
    "\n",
    "        frames = np.where(expid == (ndx + 1))[0]\n",
    "        curdir = os.path.dirname(localdirs[ndx])\n",
    "        cap = cv2.VideoCapture(localdirs[ndx])\n",
    "\n",
    "        curenv = valenv if isval.count(ndx) else env\n",
    "\n",
    "        for curl in frames:\n",
    "\n",
    "            fnum = ts[curl]\n",
    "            if fnum > cap.get(cvc.FRAME_COUNT):\n",
    "                if fnum > cap.get(cvc.FRAME_COUNT)+1:\n",
    "                    raise ValueError('Accessing frames beyond ' + \n",
    "                                     'the length of the video for' + \n",
    "                                     ' {} expid {:d} '.format(expname,ndx) + \n",
    "                                     ' at t {:d}'.format(fnum)\n",
    "                                    )\n",
    "                continue\n",
    "            framein = myutils.readframe(cap,fnum-1)\n",
    "            cloc = conf.cropLoc[tuple(framein.shape[0:2])]\n",
    "            framein = PoseTools.cropImages(framein,conf)\n",
    "            framein = framein[:,:,0:1]\n",
    "\n",
    "            curloc = np.round(pts[curl,:,view,:]).astype('int')\n",
    "            curloc[:,0] = curloc[:,0] - cloc[1]  # ugh, the nasty x-y business.\n",
    "            curloc[:,1] = curloc[:,1] - cloc[0]\n",
    "            curloc = curloc.clip(min=1)\n",
    "\n",
    "            rows = framein.shape[0]\n",
    "            cols = framein.shape[1]\n",
    "            if np.ndim(framein) > 2:\n",
    "                depth = framein.shape[2]\n",
    "            else:\n",
    "                depth = 1\n",
    "\n",
    "            image_raw = framein.tostring()\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'height': _int64_feature(rows),\n",
    "                'width': _int64_feature(cols),\n",
    "                'depth': _int64_feature(depth),\n",
    "                'locs': _float_feature(curloc.flatten()),\n",
    "                'expndx': _float_feature(ndx),\n",
    "                'ts': _float_feature(curl),\n",
    "                'image_raw': _bytes_feature(image_raw)}))\n",
    "            curenv.write(example.SerializeToString())\n",
    "\n",
    "            if isval.count(ndx):\n",
    "                valcount+=1\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "        cap.release() # close the movie handles\n",
    "        print('Done %d of %d movies, count:%d val:%d' % (ndx,len(localdirs),count,valcount))\n",
    "    env.close() # close the database\n",
    "    valenv.close()\n",
    "    print('%d,%d number of pos examples added to the db and valdb' %(count,valcount))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createFullTFRecord(conf):\n",
    "\n",
    "    L = h5py.File(conf.labelfile,'r')\n",
    "    pts = np.array(L['pts'])\n",
    "    ts = np.array(L['ts']).squeeze().astype('int')\n",
    "    expid = np.array(L['expidx']).squeeze().astype('int')\n",
    "    view = conf.view\n",
    "    count = 0; valcount = 0\n",
    "    \n",
    "    psz = conf.sel_sz\n",
    "    \n",
    "    createValdata(conf)\n",
    "    isval,localdirs,seldirs = loadValdata(conf)\n",
    "    \n",
    "    trainfilename =os.path.join(conf.cachedir,conf.fulltrainfilename)\n",
    "    \n",
    "    env = tf.python_io.TFRecordWriter(trainfilename+'.tfrecords')\n",
    "    \n",
    "    for ndx,dirname in enumerate(localdirs):\n",
    "        if not seldirs[ndx]:\n",
    "            continue\n",
    "\n",
    "        frames = np.where(expid == (ndx + 1))[0]\n",
    "        curdir = os.path.dirname(localdirs[ndx])\n",
    "        cap = cv2.VideoCapture(localdirs[ndx])\n",
    "\n",
    "        curenv = env\n",
    "\n",
    "        for curl in frames:\n",
    "\n",
    "            fnum = ts[curl]\n",
    "            if fnum > cap.get(cvc.FRAME_COUNT):\n",
    "                if fnum > cap.get(cvc.FRAME_COUNT)+1:\n",
    "                    raise ValueError('Accessing frames beyond ' + \n",
    "                                     'the length of the video for' + \n",
    "                                     ' {} expid {:d} '.format(expname,ndx) + \n",
    "                                     ' at t {:d}'.format(fnum)\n",
    "                                    )\n",
    "                continue\n",
    "            framein = myutils.readframe(cap,fnum-1)\n",
    "            cloc = conf.cropLoc[tuple(framein.shape[0:2])]\n",
    "            framein = PoseTools.cropImages(framein,conf)\n",
    "            framein = framein[:,:,0:1]\n",
    "\n",
    "            curloc = np.round(pts[curl,:,view,:]).astype('int')\n",
    "            curloc[:,0] = curloc[:,0] - cloc[1]  # ugh, the nasty x-y business.\n",
    "            curloc[:,1] = curloc[:,1] - cloc[0]\n",
    "            curloc = curloc.clip(min=0.1)\n",
    "\n",
    "            rows = framein.shape[0]\n",
    "            cols = framein.shape[1]\n",
    "            if np.ndim(framein) > 2:\n",
    "                depth = framein.shape[2]\n",
    "            else:\n",
    "                depth = 1\n",
    "\n",
    "            image_raw = framein.tostring()\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'height': _int64_feature(rows),\n",
    "                'width': _int64_feature(cols),\n",
    "                'depth': _int64_feature(depth),\n",
    "                'locs': _float_feature(curloc.flatten()),\n",
    "                'expndx': _float_feature(ndx),\n",
    "                'ts': _float_feature(curl),\n",
    "                'image_raw': _bytes_feature(image_raw)}))\n",
    "            curenv.write(example.SerializeToString())\n",
    "\n",
    "            count+=1\n",
    "\n",
    "        cap.release() # close the movie handles\n",
    "        print('Done %d of %d movies, count:%d val:%d' % (ndx,len(localdirs),count,valcount))\n",
    "    env.close() # close the database\n",
    "    print('%d,%d number of pos examples added to the db and valdb' %(count,valcount))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createTFRecordFromLbl(conf,split=True):\n",
    "\n",
    "    L = h5py.File(conf.labelfile,'r')\n",
    "    \n",
    "    \n",
    "    psz = conf.sel_sz\n",
    "    \n",
    "    createValdata(conf)\n",
    "    isval,localdirs,seldirs = loadValdata(conf)\n",
    "    \n",
    "    if split:\n",
    "        trainfilename =os.path.join(conf.cachedir,conf.trainfilename)\n",
    "        valfilename =os.path.join(conf.cachedir,conf.valfilename)\n",
    "\n",
    "        env = tf.python_io.TFRecordWriter(trainfilename+'.tfrecords')\n",
    "        valenv = tf.python_io.TFRecordWriter(valfilename+'.tfrecords')\n",
    "    else:\n",
    "        trainfilename =os.path.join(conf.cachedir,conf.fulltrainfilename)\n",
    "        env = tf.python_io.TFRecordWriter(trainfilename+'.tfrecords')\n",
    "        valenv = None\n",
    "        \n",
    "\n",
    "    pts = np.array(L['labeledpos'])\n",
    "    \n",
    "    view = conf.view\n",
    "    count = 0; valcount = 0\n",
    "    \n",
    "    \n",
    "    for ndx,dirname in enumerate(localdirs):\n",
    "        if not seldirs[ndx]:\n",
    "            continue\n",
    "\n",
    "        expname = conf.getexpname(dirname)\n",
    "        curpts = np.array(L[pts[0,ndx]])\n",
    "        zz = curpts.reshape([curpts.shape[0],-1])\n",
    "        frames = np.where(np.invert( np.any(np.isnan(curpts[:,:,:]),axis=(1,2))))[0]\n",
    "        curdir = os.path.dirname(localdirs[ndx])\n",
    "        cap = cv2.VideoCapture(localdirs[ndx])\n",
    "\n",
    "        \n",
    "        curenv = valenv if isval.count(ndx) and split else env\n",
    "            \n",
    "\n",
    "        for fnum in frames:\n",
    "\n",
    "            if fnum > cap.get(cvc.FRAME_COUNT):\n",
    "                if fnum > cap.get(cvc.FRAME_COUNT)+1:\n",
    "                    raise ValueError('Accessing frames beyond ' + \n",
    "                                     'the length of the video for' + \n",
    "                                     ' {} expid {:d} '.format(expname,ndx) + \n",
    "                                     ' at t {:d}'.format(fnum)\n",
    "                                    )\n",
    "                continue\n",
    "            framein = myutils.readframe(cap,fnum)\n",
    "            cloc = conf.cropLoc[tuple(framein.shape[0:2])]\n",
    "            framein = PoseTools.cropImages(framein,conf)\n",
    "            framein = framein[:,:,0:1]\n",
    "\n",
    "            nptsPerView = np.array(L['cfg']['NumLabelPoints'])[0,0]\n",
    "            pts_st = int(view*nptsPerView)\n",
    "            selpts = pts_st + conf.selpts\n",
    "            curloc = curpts[fnum,:,selpts]\n",
    "            curloc[:,0] = curloc[:,0] - cloc[1] - 1 # ugh, the nasty x-y business.\n",
    "            curloc[:,1] = curloc[:,1] - cloc[0] - 1\n",
    "            curloc = curloc.clip(min=0,max=[conf.imsz[1]+7,conf.imsz[0]+7])\n",
    "            \n",
    "\n",
    "            rows = framein.shape[0]\n",
    "            cols = framein.shape[1]\n",
    "            if np.ndim(framein) > 2:\n",
    "                depth = framein.shape[2]\n",
    "            else:\n",
    "                depth = 1\n",
    "\n",
    "            image_raw = framein.tostring()\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'height': _int64_feature(rows),\n",
    "                'width': _int64_feature(cols),\n",
    "                'depth': _int64_feature(depth),\n",
    "                'locs': _float_feature(curloc.flatten()),\n",
    "                'expndx': _float_feature(ndx),\n",
    "                'ts': _float_feature(fnum),\n",
    "                'image_raw': _bytes_feature(image_raw)}))\n",
    "            curenv.write(example.SerializeToString())\n",
    "\n",
    "            if isval.count(ndx) and split:\n",
    "                valcount+=1\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "        cap.release() # close the movie handles\n",
    "        print('Done %d of %d movies, count:%d val:%d' % (ndx,len(localdirs),count,valcount))\n",
    "    env.close() # close the database\n",
    "    if split:\n",
    "        valenv.close()\n",
    "    print('%d,%d number of pos examples added to the db and valdb' %(count,valcount))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue,conf):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={'height':tf.FixedLenFeature([], dtype=tf.int64),\n",
    "          'width':tf.FixedLenFeature([], dtype=tf.int64),\n",
    "          'depth':tf.FixedLenFeature([], dtype=tf.int64),\n",
    "#           'expndx': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "#           'ts': tf.FixedLenFeature([], dtype=tf.float32),\n",
    "          'locs':tf.FixedLenFeature(shape=[conf.n_classes,2], dtype=tf.float32),\n",
    "          'image_raw':tf.FixedLenFeature([], dtype=tf.string)\n",
    "                 })\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    height = tf.cast(features['height'],tf.int64)\n",
    "    width = tf.cast(features['width'],tf.int64)\n",
    "    depth = tf.cast(features['depth'],tf.int64)\n",
    "    image = tf.reshape(image,conf.imsz )\n",
    "    \n",
    "    locs = tf.cast(features['locs'], tf.float64)\n",
    "    expndx = tf.constant([0]);#tf.cast(features['expndx'],tf.float64)\n",
    "    ts = tf.constant([0]); #tf.cast(features['ts'],tf.float64)\n",
    "\n",
    "    return image, locs, [expndx,ts]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
